{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Albert Chen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imports here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset here\n",
    "file = open(\"../dataset/processed_reviews.json\", 'r', encoding='utf8')\n",
    "dataset_dict = json.load(file)\n",
    "df_raw = pd.DataFrame(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused features\n",
    "df = df_raw.copy(deep=True) #Do this so that I dont have to rerun the previous cell every time I make a change\n",
    "df.drop(columns=['firm','job_title'], inplace=True) #one hotting these would create too many features\n",
    "\n",
    "# Split up Date\n",
    "df['date'] = pd.to_datetime(df['date_review'])\n",
    "df['month'] = df['date'].dt.month.astype(str)\n",
    "df['year'] = df['date'].dt.year\n",
    "\n",
    "# Consider the length text inputs\n",
    "df['pros_length'] = df['pros'].apply(lambda x: len(x))\n",
    "df['cons_length'] = df['cons'].apply(lambda x: len(x))\n",
    "df.drop(columns=['headline', 'pros', 'cons'], inplace=True)\n",
    "\n",
    "# Encode 'current' as int\n",
    "df['current'] = (df['current'] == 'Current Employee').astype(int)\n",
    "\n",
    "# Min-max normalization\n",
    "scaler = MinMaxScaler()\n",
    "numeric_cols = df.select_dtypes(include=['int', 'float']).columns\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "#One hot encode\n",
    "one_hot_encoded = pd.get_dummies(df[['recommend', 'ceo_approv', 'outlook', 'month', 'duration']])\n",
    "df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "df.drop(columns=['date', 'date_review', 'recommend', 'ceo_approv', 'outlook', 'month', 'duration'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['current', 'overall_rating', 'work_life_balance', 'culture_values',\n",
      "       'career_opp', 'comp_benefits', 'senior_mgmt', 'year', 'pros_length',\n",
      "       'cons_length', 'recommend_o', 'recommend_v', 'recommend_x',\n",
      "       'ceo_approv_o', 'ceo_approv_r', 'ceo_approv_v', 'ceo_approv_x',\n",
      "       'outlook_o', 'outlook_r', 'outlook_v', 'outlook_x', 'month_1',\n",
      "       'month_10', 'month_11', 'month_12', 'month_2', 'month_3', 'month_4',\n",
      "       'month_5', 'month_6', 'month_7', 'month_8', 'month_9',\n",
      "       'duration_less than 1 year', 'duration_more than 1 year',\n",
      "       'duration_more than 10 years', 'duration_more than 3 years',\n",
      "       'duration_more than 5 years', 'duration_more than 8 years',\n",
      "       'duration_not mentioned'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current</th>\n",
       "      <th>overall_rating</th>\n",
       "      <th>work_life_balance</th>\n",
       "      <th>culture_values</th>\n",
       "      <th>career_opp</th>\n",
       "      <th>comp_benefits</th>\n",
       "      <th>senior_mgmt</th>\n",
       "      <th>year</th>\n",
       "      <th>pros_length</th>\n",
       "      <th>cons_length</th>\n",
       "      <th>...</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>duration_less than 1 year</th>\n",
       "      <th>duration_more than 1 year</th>\n",
       "      <th>duration_more than 10 years</th>\n",
       "      <th>duration_more than 3 years</th>\n",
       "      <th>duration_more than 5 years</th>\n",
       "      <th>duration_more than 8 years</th>\n",
       "      <th>duration_not mentioned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.011246</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.020727</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.020541</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.005726</td>\n",
       "      <td>0.022493</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   current  overall_rating  work_life_balance  culture_values  career_opp  \\\n",
       "0      1.0            0.25               0.50            0.00        0.25   \n",
       "1      1.0            0.00               0.00            0.00        0.00   \n",
       "2      1.0            0.00               0.25            0.00        0.25   \n",
       "3      1.0            0.50               0.75            0.25        0.25   \n",
       "4      0.0            0.00               0.00            0.00        0.00   \n",
       "\n",
       "   comp_benefits  senior_mgmt      year  pros_length  cons_length  ...  \\\n",
       "0            0.0         0.75  0.538462     0.002257     0.011246  ...   \n",
       "1            0.0         0.00  0.615385     0.002753     0.020727  ...   \n",
       "2            0.0         0.00  0.615385     0.001817     0.020541  ...   \n",
       "3            0.5         0.25  0.615385     0.006607     0.009573  ...   \n",
       "4            0.0         0.00  0.615385     0.005726     0.022493  ...   \n",
       "\n",
       "   month_7  month_8  month_9  duration_less than 1 year  \\\n",
       "0    False    False    False                      False   \n",
       "1    False    False    False                       True   \n",
       "2    False    False    False                      False   \n",
       "3    False    False    False                       True   \n",
       "4    False    False     True                      False   \n",
       "\n",
       "   duration_more than 1 year  duration_more than 10 years  \\\n",
       "0                       True                        False   \n",
       "1                      False                        False   \n",
       "2                       True                        False   \n",
       "3                      False                        False   \n",
       "4                      False                        False   \n",
       "\n",
       "   duration_more than 3 years  duration_more than 5 years  \\\n",
       "0                       False                       False   \n",
       "1                       False                       False   \n",
       "2                       False                       False   \n",
       "3                       False                       False   \n",
       "4                       False                       False   \n",
       "\n",
       "   duration_more than 8 years  duration_not mentioned  \n",
       "0                       False                   False  \n",
       "1                       False                   False  \n",
       "2                       False                   False  \n",
       "3                       False                   False  \n",
       "4                       False                    True  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (681651, 39) (681651,)\n",
      "Testing set shape: (75740, 39) (75740,)\n"
     ]
    }
   ],
   "source": [
    "#Spliting the data\n",
    "X = df.drop(columns=['overall_rating'])\n",
    "y = df['overall_rating']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "682/682 [==============================] - 1s 1ms/step - loss: 0.0625 - MSE: 0.0625 - val_loss: 0.0358 - val_MSE: 0.0358\n",
      "Epoch 2/100\n",
      "682/682 [==============================] - 1s 986us/step - loss: 0.0332 - MSE: 0.0332 - val_loss: 0.0320 - val_MSE: 0.0320\n",
      "Epoch 3/100\n",
      "682/682 [==============================] - 1s 912us/step - loss: 0.0312 - MSE: 0.0312 - val_loss: 0.0311 - val_MSE: 0.0311\n",
      "Epoch 4/100\n",
      "682/682 [==============================] - 1s 889us/step - loss: 0.0307 - MSE: 0.0307 - val_loss: 0.0308 - val_MSE: 0.0308\n",
      "Epoch 5/100\n",
      "682/682 [==============================] - 1s 894us/step - loss: 0.0305 - MSE: 0.0305 - val_loss: 0.0307 - val_MSE: 0.0307\n",
      "Epoch 6/100\n",
      "682/682 [==============================] - 1s 894us/step - loss: 0.0304 - MSE: 0.0304 - val_loss: 0.0306 - val_MSE: 0.0306\n",
      "Epoch 7/100\n",
      "682/682 [==============================] - 1s 897us/step - loss: 0.0303 - MSE: 0.0303 - val_loss: 0.0305 - val_MSE: 0.0305\n",
      "Epoch 8/100\n",
      "682/682 [==============================] - 1s 887us/step - loss: 0.0303 - MSE: 0.0303 - val_loss: 0.0305 - val_MSE: 0.0305\n",
      "Epoch 9/100\n",
      "682/682 [==============================] - 1s 889us/step - loss: 0.0302 - MSE: 0.0302 - val_loss: 0.0304 - val_MSE: 0.0304\n",
      "Epoch 10/100\n",
      "682/682 [==============================] - 1s 896us/step - loss: 0.0302 - MSE: 0.0302 - val_loss: 0.0304 - val_MSE: 0.0304\n",
      "Epoch 11/100\n",
      "682/682 [==============================] - 1s 894us/step - loss: 0.0302 - MSE: 0.0302 - val_loss: 0.0304 - val_MSE: 0.0304\n",
      "Epoch 12/100\n",
      "682/682 [==============================] - 1s 918us/step - loss: 0.0301 - MSE: 0.0301 - val_loss: 0.0305 - val_MSE: 0.0305\n",
      "Epoch 13/100\n",
      "682/682 [==============================] - 1s 899us/step - loss: 0.0301 - MSE: 0.0301 - val_loss: 0.0303 - val_MSE: 0.0303\n",
      "Epoch 14/100\n",
      "682/682 [==============================] - 1s 908us/step - loss: 0.0301 - MSE: 0.0301 - val_loss: 0.0303 - val_MSE: 0.0303\n",
      "Epoch 15/100\n",
      "682/682 [==============================] - 1s 897us/step - loss: 0.0301 - MSE: 0.0301 - val_loss: 0.0303 - val_MSE: 0.0303\n",
      "Epoch 16/100\n",
      "682/682 [==============================] - 1s 899us/step - loss: 0.0300 - MSE: 0.0300 - val_loss: 0.0302 - val_MSE: 0.0302\n",
      "Epoch 17/100\n",
      "682/682 [==============================] - 1s 903us/step - loss: 0.0300 - MSE: 0.0300 - val_loss: 0.0302 - val_MSE: 0.0302\n",
      "Epoch 18/100\n",
      "682/682 [==============================] - 1s 899us/step - loss: 0.0300 - MSE: 0.0300 - val_loss: 0.0302 - val_MSE: 0.0302\n",
      "Epoch 19/100\n",
      "682/682 [==============================] - 1s 896us/step - loss: 0.0300 - MSE: 0.0300 - val_loss: 0.0302 - val_MSE: 0.0302\n",
      "Epoch 20/100\n",
      "682/682 [==============================] - 1s 899us/step - loss: 0.0299 - MSE: 0.0299 - val_loss: 0.0301 - val_MSE: 0.0301\n",
      "Epoch 21/100\n",
      "682/682 [==============================] - 1s 1ms/step - loss: 0.0299 - MSE: 0.0299 - val_loss: 0.0301 - val_MSE: 0.0301\n",
      "Epoch 22/100\n",
      "682/682 [==============================] - 1s 949us/step - loss: 0.0299 - MSE: 0.0299 - val_loss: 0.0301 - val_MSE: 0.0301\n",
      "Epoch 23/100\n",
      "682/682 [==============================] - 1s 917us/step - loss: 0.0299 - MSE: 0.0299 - val_loss: 0.0301 - val_MSE: 0.0301\n",
      "Epoch 24/100\n",
      "682/682 [==============================] - 1s 922us/step - loss: 0.0298 - MSE: 0.0298 - val_loss: 0.0301 - val_MSE: 0.0301\n",
      "Epoch 25/100\n",
      "682/682 [==============================] - 1s 906us/step - loss: 0.0298 - MSE: 0.0298 - val_loss: 0.0300 - val_MSE: 0.0300\n",
      "Epoch 26/100\n",
      "682/682 [==============================] - 1s 908us/step - loss: 0.0298 - MSE: 0.0298 - val_loss: 0.0301 - val_MSE: 0.0301\n",
      "Epoch 27/100\n",
      "682/682 [==============================] - 1s 924us/step - loss: 0.0298 - MSE: 0.0298 - val_loss: 0.0300 - val_MSE: 0.0300\n",
      "Epoch 28/100\n",
      "682/682 [==============================] - 1s 934us/step - loss: 0.0297 - MSE: 0.0297 - val_loss: 0.0300 - val_MSE: 0.0300\n",
      "Epoch 29/100\n",
      "682/682 [==============================] - 1s 937us/step - loss: 0.0297 - MSE: 0.0297 - val_loss: 0.0299 - val_MSE: 0.0299\n",
      "Epoch 30/100\n",
      "682/682 [==============================] - 1s 924us/step - loss: 0.0297 - MSE: 0.0297 - val_loss: 0.0300 - val_MSE: 0.0300\n",
      "Epoch 31/100\n",
      "682/682 [==============================] - 1s 921us/step - loss: 0.0297 - MSE: 0.0297 - val_loss: 0.0299 - val_MSE: 0.0299\n",
      "Epoch 32/100\n",
      "682/682 [==============================] - 1s 922us/step - loss: 0.0297 - MSE: 0.0297 - val_loss: 0.0298 - val_MSE: 0.0298\n",
      "Epoch 33/100\n",
      "682/682 [==============================] - 1s 919us/step - loss: 0.0296 - MSE: 0.0296 - val_loss: 0.0298 - val_MSE: 0.0298\n",
      "Epoch 34/100\n",
      "682/682 [==============================] - 1s 941us/step - loss: 0.0296 - MSE: 0.0296 - val_loss: 0.0298 - val_MSE: 0.0298\n",
      "Epoch 35/100\n",
      "682/682 [==============================] - 1s 914us/step - loss: 0.0296 - MSE: 0.0296 - val_loss: 0.0298 - val_MSE: 0.0298\n",
      "Epoch 36/100\n",
      "682/682 [==============================] - 1s 928us/step - loss: 0.0296 - MSE: 0.0296 - val_loss: 0.0298 - val_MSE: 0.0298\n",
      "Epoch 37/100\n",
      "682/682 [==============================] - 1s 940us/step - loss: 0.0295 - MSE: 0.0295 - val_loss: 0.0297 - val_MSE: 0.0297\n",
      "Epoch 38/100\n",
      "682/682 [==============================] - 1s 924us/step - loss: 0.0295 - MSE: 0.0295 - val_loss: 0.0297 - val_MSE: 0.0297\n",
      "Epoch 39/100\n",
      "682/682 [==============================] - 1s 908us/step - loss: 0.0295 - MSE: 0.0295 - val_loss: 0.0297 - val_MSE: 0.0297\n",
      "Epoch 40/100\n",
      "682/682 [==============================] - 1s 928us/step - loss: 0.0295 - MSE: 0.0295 - val_loss: 0.0297 - val_MSE: 0.0297\n",
      "Epoch 41/100\n",
      "682/682 [==============================] - 1s 887us/step - loss: 0.0294 - MSE: 0.0294 - val_loss: 0.0296 - val_MSE: 0.0296\n",
      "Epoch 42/100\n",
      "682/682 [==============================] - 1s 872us/step - loss: 0.0294 - MSE: 0.0294 - val_loss: 0.0296 - val_MSE: 0.0296\n",
      "Epoch 43/100\n",
      "682/682 [==============================] - 1s 877us/step - loss: 0.0294 - MSE: 0.0294 - val_loss: 0.0297 - val_MSE: 0.0297\n",
      "Epoch 44/100\n",
      "682/682 [==============================] - 1s 877us/step - loss: 0.0294 - MSE: 0.0294 - val_loss: 0.0296 - val_MSE: 0.0296\n",
      "Epoch 45/100\n",
      "682/682 [==============================] - 1s 915us/step - loss: 0.0294 - MSE: 0.0294 - val_loss: 0.0296 - val_MSE: 0.0296\n",
      "Epoch 46/100\n",
      "682/682 [==============================] - 1s 897us/step - loss: 0.0293 - MSE: 0.0293 - val_loss: 0.0295 - val_MSE: 0.0295\n",
      "Epoch 47/100\n",
      "682/682 [==============================] - 1s 894us/step - loss: 0.0293 - MSE: 0.0293 - val_loss: 0.0295 - val_MSE: 0.0295\n",
      "Epoch 48/100\n",
      "682/682 [==============================] - 1s 911us/step - loss: 0.0293 - MSE: 0.0293 - val_loss: 0.0295 - val_MSE: 0.0295\n",
      "Epoch 49/100\n",
      "682/682 [==============================] - 1s 928us/step - loss: 0.0293 - MSE: 0.0293 - val_loss: 0.0295 - val_MSE: 0.0295\n",
      "Epoch 50/100\n",
      "682/682 [==============================] - 1s 908us/step - loss: 0.0293 - MSE: 0.0293 - val_loss: 0.0295 - val_MSE: 0.0295\n",
      "Epoch 51/100\n",
      "682/682 [==============================] - 1s 884us/step - loss: 0.0293 - MSE: 0.0293 - val_loss: 0.0295 - val_MSE: 0.0295\n",
      "Epoch 52/100\n",
      "682/682 [==============================] - 1s 878us/step - loss: 0.0292 - MSE: 0.0292 - val_loss: 0.0294 - val_MSE: 0.0294\n",
      "Epoch 53/100\n",
      "682/682 [==============================] - 1s 884us/step - loss: 0.0292 - MSE: 0.0292 - val_loss: 0.0296 - val_MSE: 0.0296\n",
      "Epoch 54/100\n",
      "682/682 [==============================] - 1s 896us/step - loss: 0.0292 - MSE: 0.0292 - val_loss: 0.0294 - val_MSE: 0.0294\n",
      "Epoch 55/100\n",
      "682/682 [==============================] - 1s 894us/step - loss: 0.0292 - MSE: 0.0292 - val_loss: 0.0294 - val_MSE: 0.0294\n",
      "Epoch 56/100\n",
      "682/682 [==============================] - 1s 897us/step - loss: 0.0292 - MSE: 0.0292 - val_loss: 0.0294 - val_MSE: 0.0294\n",
      "Epoch 57/100\n",
      "682/682 [==============================] - 1s 878us/step - loss: 0.0292 - MSE: 0.0292 - val_loss: 0.0294 - val_MSE: 0.0294\n",
      "Epoch 58/100\n",
      "682/682 [==============================] - 1s 878us/step - loss: 0.0292 - MSE: 0.0292 - val_loss: 0.0294 - val_MSE: 0.0294\n",
      "Epoch 59/100\n",
      "682/682 [==============================] - 1s 896us/step - loss: 0.0292 - MSE: 0.0292 - val_loss: 0.0294 - val_MSE: 0.0294\n",
      "Epoch 60/100\n",
      "682/682 [==============================] - 1s 887us/step - loss: 0.0291 - MSE: 0.0291 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 61/100\n",
      "682/682 [==============================] - 1s 941us/step - loss: 0.0291 - MSE: 0.0291 - val_loss: 0.0294 - val_MSE: 0.0294\n",
      "Epoch 62/100\n",
      "682/682 [==============================] - 1s 911us/step - loss: 0.0291 - MSE: 0.0291 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 63/100\n",
      "682/682 [==============================] - 1s 893us/step - loss: 0.0291 - MSE: 0.0291 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 64/100\n",
      "682/682 [==============================] - 1s 903us/step - loss: 0.0291 - MSE: 0.0291 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 65/100\n",
      "682/682 [==============================] - 1s 911us/step - loss: 0.0291 - MSE: 0.0291 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 66/100\n",
      "682/682 [==============================] - 1s 908us/step - loss: 0.0291 - MSE: 0.0291 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 67/100\n",
      "682/682 [==============================] - 1s 903us/step - loss: 0.0291 - MSE: 0.0291 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 68/100\n",
      "682/682 [==============================] - 1s 893us/step - loss: 0.0291 - MSE: 0.0291 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 69/100\n",
      "682/682 [==============================] - 1s 890us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 70/100\n",
      "682/682 [==============================] - 1s 894us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 71/100\n",
      "682/682 [==============================] - 1s 892us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 72/100\n",
      "682/682 [==============================] - 1s 887us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 73/100\n",
      "682/682 [==============================] - 1s 893us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 74/100\n",
      "682/682 [==============================] - 1s 905us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 75/100\n",
      "682/682 [==============================] - 1s 919us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 76/100\n",
      "682/682 [==============================] - 1s 981us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 77/100\n",
      "682/682 [==============================] - 1s 941us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 78/100\n",
      "682/682 [==============================] - 1s 924us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 79/100\n",
      "682/682 [==============================] - 1s 928us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 80/100\n",
      "682/682 [==============================] - 1s 931us/step - loss: 0.0290 - MSE: 0.0290 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 81/100\n",
      "682/682 [==============================] - 1s 921us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0293 - val_MSE: 0.0293\n",
      "Epoch 82/100\n",
      "682/682 [==============================] - 1s 930us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 83/100\n",
      "682/682 [==============================] - 1s 905us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 84/100\n",
      "682/682 [==============================] - 1s 906us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 85/100\n",
      "682/682 [==============================] - 1s 915us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 86/100\n",
      "682/682 [==============================] - 1s 899us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 87/100\n",
      "682/682 [==============================] - 1s 890us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 88/100\n",
      "682/682 [==============================] - 1s 908us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0292 - val_MSE: 0.0292\n",
      "Epoch 89/100\n",
      "682/682 [==============================] - 1s 894us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 90/100\n",
      "682/682 [==============================] - 1s 886us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 91/100\n",
      "682/682 [==============================] - 1s 887us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 92/100\n",
      "682/682 [==============================] - 1s 887us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 93/100\n",
      "682/682 [==============================] - 1s 924us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 94/100\n",
      "682/682 [==============================] - 1s 889us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 95/100\n",
      "682/682 [==============================] - 1s 887us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 96/100\n",
      "682/682 [==============================] - 1s 925us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0290 - val_MSE: 0.0290\n",
      "Epoch 97/100\n",
      "682/682 [==============================] - 1s 903us/step - loss: 0.0289 - MSE: 0.0289 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 98/100\n",
      "682/682 [==============================] - 1s 931us/step - loss: 0.0288 - MSE: 0.0288 - val_loss: 0.0290 - val_MSE: 0.0290\n",
      "Epoch 99/100\n",
      "682/682 [==============================] - 1s 919us/step - loss: 0.0288 - MSE: 0.0288 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "Epoch 100/100\n",
      "682/682 [==============================] - 1s 909us/step - loss: 0.0288 - MSE: 0.0288 - val_loss: 0.0291 - val_MSE: 0.0291\n",
      "682/682 [==============================] - 0s 580us/step\n",
      "76/76 [==============================] - 0s 547us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.520309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.679825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.977790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.304865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75735</th>\n",
       "      <td>0.705612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75736</th>\n",
       "      <td>0.952504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75737</th>\n",
       "      <td>0.948717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75738</th>\n",
       "      <td>0.977892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75739</th>\n",
       "      <td>0.975726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75740 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      0.219080\n",
       "1      0.520309\n",
       "2      0.679825\n",
       "3      0.977790\n",
       "4      0.304865\n",
       "...         ...\n",
       "75735  0.705612\n",
       "75736  0.952504\n",
       "75737  0.948717\n",
       "75738  0.977892\n",
       "75739  0.975726\n",
       "\n",
       "[75740 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def buildReluNN():\n",
    "    model = Sequential([\n",
    "        Dense(32, activation = 'relu', input_dim = X.shape[1]),\n",
    "        Dense(16, activation = 'relu'),\n",
    "        Dense(8, activation = 'relu'),\n",
    "        Dense(4, activation = 'relu'),\n",
    "        Dense(1, activation = 'sigmoid'),\n",
    "    ])\n",
    "    optimizer = SGD(learning_rate=0.1)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['MSE'])\n",
    "    return(model)\n",
    "\n",
    "estimator = KerasRegressor(model=buildReluNN, epochs=100, batch_size=1000, verbose=1)\n",
    "history = estimator.fit(X_train, y_train, validation_data=(X_test.astype('float'), y_test))\n",
    "y_train_pred = estimator.predict(X_train)\n",
    "y_test_pred = estimator.predict(X_test)\n",
    "pd.DataFrame(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029163377991230626\n"
     ]
    }
   ],
   "source": [
    "MSE = sum((y_test_pred - y_test)**2)/y_test.size\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3375312127232222\n"
     ]
    }
   ],
   "source": [
    "# Fraction of Variance Unexplained\n",
    "FVU = MSE/np.var(y_test)\n",
    "print(FVU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5958146289939266"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_scaled = np.round((y_test_pred*4))\n",
    "y_test_scaled = y_test*4\n",
    "accuracy = (y_test_pred_scaled == y_test_scaled).sum()/len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028879590993752053\n"
     ]
    }
   ],
   "source": [
    "#Training MSE and FVU\n",
    "MSE = sum((y_train_pred - y_train)**2)/y_train.size\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3327577871770848\n"
     ]
    }
   ],
   "source": [
    "FVU = MSE/np.var(y_train)\n",
    "print(FVU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildHPmodel(hp):\n",
    "  model= Sequential([\n",
    "      Dense(32, activation = 'relu', input_dim = X.shape[1]),\n",
    "      Dense(\n",
    "              units=hp.Int(\"units\", min_value=8, max_value=24, step=4),\n",
    "              activation= 'relu',\n",
    "      ),\n",
    "      Dense(\n",
    "              units=hp.Int(\"units\", min_value=4, max_value=16, step=4),\n",
    "              activation= 'relu',\n",
    "      ),\n",
    "      Dense(\n",
    "              units=hp.Int(\"units\", min_value=1, max_value=8, step=4),\n",
    "              activation= 'relu',\n",
    "      ),\n",
    "      Dense(1, activation = 'sigmoid')\n",
    "  ])\n",
    "\n",
    "  optimizer = SGD(learning_rate=0.3)\n",
    "  model.compile(optimizer=optimizer, loss='mse', metrics=['MSE'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 01m 21s]\n",
      "val_loss: 0.02869807370007038\n",
      "\n",
      "Best val_loss So Far: 0.02869807370007038\n",
      "Total elapsed time: 00h 12m 06s\n"
     ]
    }
   ],
   "source": [
    "hp = keras_tuner.HyperParameters()\n",
    "\n",
    "tuner = keras_tuner.GridSearch(\n",
    "    hypermodel=buildHPmodel,\n",
    "    objective=\"val_loss\",\n",
    "    max_trials=10,\n",
    "    seed=0,\n",
    "    executions_per_trial=1,\n",
    "    hyperparameters=hp,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    max_consecutive_failed_trials=3,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "X_train = np.asarray(X_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.float32)\n",
    "X_test = np.asarray(X_test).astype(np.float32)\n",
    "y_test = np.asarray(y_test).astype(np.float32)\n",
    "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in .\\untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "units: 24\n",
      "Score: 0.02869807370007038\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "units: 14\n",
      "Score: 0.028774499893188477\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "units: 22\n",
      "Score: 0.028802407905459404\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "units: 8\n",
      "Score: 0.02884363941848278\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "units: 10\n",
      "Score: 0.02884863130748272\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "units: 16\n",
      "Score: 0.02886430360376835\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "units: 18\n",
      "Score: 0.02886887826025486\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "units: 12\n",
      "Score: 0.028917666524648666\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "units: 20\n",
      "Score: 0.028966402634978294\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning - Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HPmodel(hp):\n",
    "    model = Sequential([\n",
    "        Dense(hp.Int(\"units\", min_value=32, max_value=64, step=2), activation = hp.Choice(\"activation\", [\"relu\", \"sigmoid\", \"softmax\", \"tanh\"]), input_dim = X.shape[1]),\n",
    "        Dense(hp.Int(\"units\", min_value=32, max_value=256, step=8), activation = hp.Choice(\"activation\", [\"relu\", \"sigmoid\", \"softmax\", \"tanh\"])),\n",
    "        Dense(hp.Int(\"units\", min_value=32, max_value=128, step=4), activation = hp.Choice(\"activation\", [\"relu\", \"sigmoid\", \"softmax\", \"tanh\"])),\n",
    "        Dense(hp.Int(\"units\", min_value=32, max_value=64, step=4), activation = hp.Choice(\"activation\", [\"relu\", \"sigmoid\", \"softmax\", \"tanh\"])),\n",
    "        Dense(1, activation = 'sigmoid'),\n",
    "    ])\n",
    "\n",
    "    learning_rate = hp.Float('lr', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    optimizer = SGD(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['MSE'])\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    HPmodel,\n",
    "    overwrite = True,\n",
    "    objective='val_loss',\n",
    "    max_trials = 20,\n",
    "    max_consecutive_failed_trials=3\n",
    ")\n",
    "tuner.search(np.array(X_train).astype('float32'), y_train, epochs=5, validation_data=(np.array(X_test).astype('float32'), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models()[0]\n",
    "print(model.summary())\n",
    "y_pred = model.predict(np.array(X_test).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = y_pred.reshape(75740,)\n",
    "MSE = sum((y_test_pred - y_test)**2)/y_test.size\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FVU = MSE/np.var(y_test)\n",
    "print(FVU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABheElEQVR4nO3deXwTZf4H8M8kaZKe6UUvBApYKPdVqAUVkK6tonK5AlYuWVmVu4qKIocsFmRhQUERVwX9gSCusIoK1gqKUG4QQUBlgXL0oJQ2PZMmmd8f005JDyylzQzweb9e82o782TyZOzSz37neZ4RRFEUQUREREQyjdIdICIiIlIbBiQiIiKiShiQiIiIiCphQCIiIiKqhAGJiIiIqBIGJCIiIqJKGJCIiIiIKmFAIiIiIqqEAYmIiIioEgYkIqI/sWrVKgiCgDNnzlz3a2fPng1BEOq/U0TUoBiQiOhPHTt2DE888QQaN24Mg8GAsLAwJCQk4NixYy7tR58+fSAIAiIiIqo9npycDEEQIAgCPvvsM5f27UaNHj0aXl5eSneDiMowIBHRNX3++efo2rUrUlJSMGbMGLz99tsYO3Ystm3bhq5du2Ljxo0u7Y/RaMQff/yBvXv3Vjm2Zs0aGI1Gl/aHiG5NOqU7QETqderUKYwYMQItWrTAjz/+iEaNGsnHJk+ejHvuuQcjRozAkSNH0KJFixt+P4fDAavVes2Q07JlS9hsNnzyySfo0aOHvL+kpAQbN25E//798Z///OeG+0JEtzdWkIioRgsXLkRRURFWrlzpFI4AIDAwEO+++y4KCwvxxhtvyPtHjx6N8PDwKueqbiyOIAiYMGEC1qxZg3bt2sFgMGDLli1/2q/hw4dj/fr1cDgc8r4vv/wSRUVFeOyxx6p9zaFDh/DAAw/Ax8cHXl5e6NevH3bv3l2l3bFjx3DffffB3d0dd9xxB/7xj384vc/VvvnmG9xzzz3w9PSEt7c3+vfv3+C3HTds2IBu3brB3d0dgYGBeOKJJ3DhwgWnNhkZGRgzZgzuuOMOGAwGhIaGYsCAAU5jqPbv34+4uDgEBgbC3d0dzZs3x5NPPtmgfSe6mbCCREQ1+vLLLxEeHo577rmn2uP33nsvwsPD8dVXX9X5Pb7//nt8+umnmDBhAgIDA6sNV5U9/vjjmD17NrZv34777rsPALB27Vr069cPQUFBVdofO3YM99xzD3x8fPDCCy/Azc0N7777Lvr06YMffvgB0dHRAKRg0bdvX9hsNrz00kvw9PTEypUr4e7uXuWcH3/8MUaNGoW4uDgsWLAARUVFeOedd3D33Xfj0KFDtfoc12vVqlUYM2YMunfvjqSkJGRmZmLp0qXYuXMnDh06BF9fXwDAkCFDcOzYMUycOBHh4eHIyspCcnIy0tLS5J/vv/9+NGrUCC+99BJ8fX1x5swZfP755/XeZ6KblkhEVI3c3FwRgDhgwIBrtnvkkUdEAKLZbBZFURRHjRolNmvWrEq7WbNmiZX/yQEgajQa8dixY7XqU+/evcV27dqJoiiKUVFR4tixY0VRFMUrV66Ier1eXL16tbht2zYRgLhhwwb5dQMHDhT1er146tQped/FixdFb29v8d5775X3TZkyRQQg7tmzR96XlZUlmkwmEYB4+vRpURRFMT8/X/T19RWfeuopp/5lZGSIJpPJaX91n7s6o0aNEj09PWs8brVaxaCgILF9+/ZicXGxvH/z5s0iAHHmzJnytQAgLly4sMZzbdy4UQQg7tu370/7RXS74i02IqpWfn4+AMDb2/ua7cqPm83mOr1P79690bZt2+t+3eOPP47PP/8cVqsVn332GbRaLQYNGlSlnd1ux7fffouBAwc6jZMKDQ3F448/jp9++knu+9dff4277rrLaWxTo0aNkJCQ4HTO5ORk5ObmYvjw4cjOzpY3rVaL6OhobNu27bo/z5/Zv38/srKy8OyzzzqN0erfvz8iIyPlKp67uzv0ej22b9+OK1euVHuu8krT5s2bUVpaWu99JboVMCARUbXKg095UKpJbYNUTZo3b16n1w0bNgx5eXn45ptvsGbNGjz00EPV9uHSpUsoKipC69atqxxr06YNHA4Hzp07BwA4e/ZstUsIVH7t77//DgC477770KhRI6ft22+/RVZWVp0+07WcPXu22r4AQGRkpHzcYDBgwYIF+OabbxAcHIx7770Xb7zxBjIyMuT2vXv3xpAhQzBnzhwEBgZiwIAB+PDDD2GxWOq930Q3K45BIqJqmUwmhIaG4siRI9dsd+TIETRu3Bg+Pj4AUOOiiHa7vdr91Y3vqY3Q0FD06dMHixYtws6dO106c6180PbHH3+MkJCQKsd1OmX/aZ0yZQoefvhhbNq0CVu3bsWrr76KpKQkfP/99+jSpYu8TtTu3bvx5ZdfYuvWrXjyySexaNEi7N69m+sxEYEVJCK6hoceeginT5/GTz/9VO3xHTt24MyZM3jooYfkfX5+fsjNza3StrzCUZ8ef/xx7NixAz4+PnjwwQerbdOoUSN4eHjg5MmTVY6dOHECGo0GTZo0AQA0a9ZMrg5drfJrW7ZsCQAICgpCbGxsla1Pnz43+MmqatasWbV9Kd9XfvzqPj733HP49ttvcfToUVitVixatMipzV133YV58+Zh//79WLNmDY4dO4Z169bVe9+JbkYMSERUo2nTpsHd3R1///vfcfnyZadjOTk5ePrpp+Hh4YFp06bJ+1u2bIm8vDynylN6enqDLCj56KOPYtasWXj77beh1+urbaPVanH//ffjv//9r9M098zMTKxduxZ33323XP168MEHsXv3bqdFKC9duoQ1a9Y4nTMuLg4+Pj54/fXXqx3Dc+nSpXr4dM6ioqIQFBSEFStWON0K++abb3D8+HH0798fAFBUVISSkhKn17Zs2RLe3t7y665cuQJRFJ3adO7cGQB4m42oDG+xEVGNIiIisHr1aiQkJKBDhw4YO3YsmjdvjjNnzuD9999HdnY2PvnkE7miAkhjg1588UUMGjQIkyZNkqe/t2rVCgcPHqzX/plMJsyePftP2/3jH/9AcnIy7r77bjz77LPQ6XR49913YbFYnNZweuGFF/Dxxx8jPj4ekydPlqf5N2vWzCnw+fj44J133sGIESPQtWtXDBs2DI0aNUJaWhq++uor9OrVC8uWLbvuz1NaWop//OMfVfb7+/vj2WefxYIFCzBmzBj07t0bw4cPl6f5h4eHY+rUqQCA3377Df369cNjjz2Gtm3bQqfTYePGjcjMzMSwYcMAAKtXr8bbb7+NQYMGoWXLlsjPz8d77713zUoc0W1H6Wl0RKR+R44cEYcPHy6GhoaKbm5uYkhIiDh8+HDxl19+qbb9t99+K7Zv317U6/Vi69atxf/7v/+rcZr/+PHja92Pq6f516S6af6iKIoHDx4U4+LiRC8vL9HDw0Ps27evuGvXrmo/a+/evUWj0Sg2btxYnDt3rvj+++87TfO/+r3i4uJEk8kkGo1GsWXLluLo0aPF/fv3y22uZ5o/gGq3li1byu3Wr18vdunSRTQYDKK/v7+YkJAgnj9/Xj6enZ0tjh8/XoyMjBQ9PT1Fk8kkRkdHi59++qnTtRg+fLjYtGlT0WAwiEFBQeJDDz3k1G+i250gipXqrERERES3OY5BIiIiIqqEAYmIiIioEgYkIiIiokoYkIiIiIgqYUAiIiIiqoQBiYiIiKgSLhRZRw6HAxcvXoS3t3eNz54iIiIidRFFEfn5+QgLC4NGU3OdiAGpji5evCg/v4mIiIhuLufOncMdd9xR43EGpDry9vYGIF3g8uc4ERERkbqZzWY0adJE/jteEwakOiq/rebj48OAREREdJP5s+ExHKRNREREVAkDEhEREVElDEhERERElXAMEhERKcJut6O0tFTpbtAtxs3NDVqt9obPw4BEREQuJYoiMjIykJubq3RX6Bbl6+uLkJCQG1qnkAGJiIhcqjwcBQUFwcPDg4vtUr0RRRFFRUXIysoCAISGhtb5XAxIRETkMna7XQ5HAQEBSneHbkHu7u4AgKysLAQFBdX5dhsHaRMRkcuUjzny8PBQuCd0Kyv//bqRMW4MSERE5HK8rUYNqT5+vxiQiIiIiCphQCIiIlJIeHg4lixZonQ3qBoMSERERH9CEIRrbrNnz67Tefft24dx48bdUN/69OmDKVOm3NA5qCrOYlOZywUWFFnt8PfUw9PA/zxERGqQnp4uf79+/XrMnDkTJ0+elPd5eXnJ34uiCLvdDp3uz/8Nb9SoUf12lOoNK0gqM2X9YdzzxjYk/5qpdFeIiKhMSEiIvJlMJgiCIP984sQJeHt745tvvkG3bt1gMBjw008/4dSpUxgwYACCg4Ph5eWF7t2747vvvnM6b+VbbIIg4N///jcGDRoEDw8PRERE4Isvvrihvv/nP/9Bu3btYDAYEB4ejkWLFjkdf/vttxEREQGj0Yjg4GA8+uij8rHPPvsMHTp0gLu7OwICAhAbG4vCwsIb6s/NgiUKldFqpJH3NoeocE+IiFxDFEUUl9oVeW93N229zah76aWX8M9//hMtWrSAn58fzp07hwcffBDz5s2DwWDARx99hIcffhgnT55E06ZNazzPnDlz8MYbb2DhwoV46623kJCQgLNnz8Lf3/+6+3TgwAE89thjmD17NoYOHYpdu3bh2WefRUBAAEaPHo39+/dj0qRJ+Pjjj9GzZ0/k5ORgx44dAKSq2fDhw/HGG29g0KBByM/Px44dOyCKt8ffJwYkldGVBSS7w6FwT4iIXKO41I62M7cq8t6/vhYHD339/Cl87bXX8Je//EX+2d/fH506dZJ/njt3LjZu3IgvvvgCEyZMqPE8o0ePxvDhwwEAr7/+Ot58803s3bsX8fHx192nxYsXo1+/fnj11VcBAK1atcKvv/6KhQsXYvTo0UhLS4OnpyceeugheHt7o1mzZujSpQsAKSDZbDYMHjwYzZo1AwB06NDhuvtws+ItNpVhBYmI6OYUFRXl9HNBQQGef/55tGnTBr6+vvDy8sLx48eRlpZ2zfN07NhR/t7T0xM+Pj7yozOu1/Hjx9GrVy+nfb169cLvv/8Ou92Ov/zlL2jWrBlatGiBESNGYM2aNSgqKgIAdOrUCf369UOHDh3w17/+Fe+99x6uXLlSp37cjFhBUhmdRsqsdgYkIrpNuLtp8etrcYq9d33x9PR0+vn5559HcnIy/vnPf+LOO++Eu7s7Hn30UVit1muex83NzelnQRDgaKC7Ct7e3jh48CC2b9+Ob7/9FjNnzsTs2bOxb98++Pr6Ijk5Gbt27cK3336Lt956C6+88gr27NmD5s2bN0h/1IQBSWXkCpKdAYmIbg+CINTbbS412blzJ0aPHo1BgwYBkCpKZ86ccWkf2rRpg507d1bpV6tWreRnlOl0OsTGxiI2NhazZs2Cr68vvv/+ewwePBiCIKBXr17o1asXZs6ciWbNmmHjxo1ITEx06edQwq33G3mTqxiDxIBERHQzi4iIwOeff46HH34YgiDg1VdfbbBK0KVLl3D48GGnfaGhoXjuuefQvXt3zJ07F0OHDkVqaiqWLVuGt99+GwCwefNm/O9//8O9994LPz8/fP3113A4HGjdujX27NmDlJQU3H///QgKCsKePXtw6dIltGnTpkE+g9owIKkMxyAREd0aFi9ejCeffBI9e/ZEYGAgXnzxRZjN5gZ5r7Vr12Lt2rVO++bOnYsZM2bg008/xcyZMzF37lyEhobitddew+jRowEAvr6++PzzzzF79myUlJQgIiICn3zyCdq1a4fjx4/jxx9/xJIlS2A2m9GsWTMsWrQIDzzwQIN8BrURxNtlvl49M5vNMJlMyMvLg4+PT72dd/rnR/DJ3nN4/v5WmHBfRL2dl4hIDUpKSnD69Gk0b94cRqNR6e7QLepav2e1/fvNWWwqwwoSERGR8hiQVIaz2IiIiJTHgKQyrCAREREpjwFJZTiLjYiISHkMSCrDdZCIiIiUx4CkMnwWGxERkfIYkFRGWzZIm2OQiIiIlMOApDI6LccgERERKY0BSWU4i42IiEh5DEgqw1lsRES3rj59+mDKlCnyz+Hh4ViyZMk1XyMIAjZt2nTD711f57ldMCCpDCtIRETq8/DDDyM+Pr7aYzt27IAgCDhy5Mh1n3ffvn0YN27cjXbPyezZs9G5c+cq+9PT0xv8OWqrVq2Cr69vg76HqzAgqQxnsRERqc/YsWORnJyM8+fPVzn24YcfIioqCh07drzu8zZq1AgeHh710cU/FRISAoPB4JL3uhUwIKmMPIuN6yAREanGQw89hEaNGmHVqlVO+wsKCrBhwwaMHTsWly9fxvDhw9G4cWN4eHigQ4cO+OSTT6553sq32H7//Xfce++9MBqNaNu2LZKTk6u85sUXX0SrVq3g4eGBFi1a4NVXX0VpaSkAqYIzZ84c/PzzzxAEAYIgyH2ufIvtl19+wX333Qd3d3cEBARg3LhxKCgokI+PHj0aAwcOxD//+U+EhoYiICAA48ePl9+rLtLS0jBgwAB4eXnBx8cHjz32GDIzM+XjP//8M/r27Qtvb2/4+PigW7du2L9/PwDg7NmzePjhh+Hn5wdPT0+0a9cOX3/9dZ378mcUD0jLly9HeHg4jEYjoqOjsXfv3mu237BhAyIjI2E0GtGhQ4dqL87x48fxyCOPwGQywdPTE927d0daWpp8vKSkBOPHj0dAQAC8vLwwZMgQp/9ASuIYJCK67YgiYC1UZhNr92+tTqfDyJEjsWrVKohXvWbDhg2w2+0YPnw4SkpK0K1bN3z11Vc4evQoxo0bhxEjRvzp37VyDocDgwcPhl6vx549e7BixQq8+OKLVdp5e3tj1apV+PXXX7F06VK89957+Ne//gUAGDp0KJ577jm0a9cO6enpSE9Px9ChQ6uco7CwEHFxcfDz88O+ffuwYcMGfPfdd5gwYYJTu23btuHUqVPYtm0bVq9ejVWrVlUJibXlcDgwYMAA5OTk4IcffkBycjL+97//OfUvISEBd9xxB/bt24cDBw7gpZdegpubGwBg/PjxsFgs+PHHH/HLL79gwYIF8PLyqlNfakPXYGeuhfXr1yMxMRErVqxAdHQ0lixZgri4OJw8eRJBQUFV2u/atQvDhw9HUlISHnroIaxduxYDBw7EwYMH0b59ewDAqVOncPfdd2Ps2LGYM2cOfHx8cOzYMRiNRvk8U6dOxVdffYUNGzbAZDJhwoQJGDx4MHbu3Omyz14TjkEiottOaRHwepgy7/3yRUDvWaumTz75JBYuXIgffvgBffr0ASDdXhsyZAhMJhNMJhOef/55uf3EiROxdetWfPrpp+jRo8efnv+7777DiRMnsHXrVoSFSdfj9ddfrzJuaMaMGfL34eHheP7557Fu3Tq88MILcHd3h5eXF3Q6HUJCQmp8r7Vr16KkpAQfffQRPD2lz79s2TI8/PDDWLBgAYKDgwEAfn5+WLZsGbRaLSIjI9G/f3+kpKTgqaeeqtU1u1pKSgp++eUXnD59Gk2aNAEAfPTRR2jXrh327dsnFzOmTZuGyMhIAEBERIT8+rS0NAwZMgQdOnQAALRo0eK6+3A9FK0gLV68GE899RTGjBmDtm3bYsWKFfDw8MAHH3xQbfulS5ciPj4e06ZNQ5s2bTB37lx07doVy5Ytk9u88sorePDBB/HGG2+gS5cuaNmyJR555BE5cOXl5eH999/H4sWLcd9996Fbt2748MMPsWvXLuzevdsln/tatKwgERGpUmRkJHr27Cn/jfrjjz+wY8cOjB07FgBgt9sxd+5cdOjQAf7+/vDy8sLWrVud7mBcy/Hjx9GkSRM5HAFATExMlXbr169Hr169EBISAi8vL8yYMaPW73H1e3Xq1EkORwDQq1cvOBwOnDx5Ut7Xrl07aLVa+efQ0FBkZWVd13td/Z5NmjSRwxEAtG3bFr6+vjh+/DgAIDExEX/7298QGxuL+fPn49SpU3LbSZMm4R//+Ad69eqFWbNm1WlQ/PVQrIJktVpx4MABTJ8+Xd6n0WgQGxuL1NTUal+TmpqKxMREp31xcXHyPVWHw4GvvvoKL7zwAuLi4nDo0CE0b94c06dPx8CBAwEABw4cQGlpKWJjY+VzREZGomnTpkhNTcVdd91V7XtbLBZYLBb5Z7PZXJeP/acqKkgcpE1Etwk3D6mSo9R7X4exY8di4sSJWL58OT788EO0bNkSvXv3BgAsXLgQS5cuxZIlS9ChQwd4enpiypQpsFqt9dbd1NRUJCQkYM6cOYiLi4PJZMK6deuwaNGienuPq5Xf3ionCAIcDfj3afbs2Xj88cfx1Vdf4ZtvvsGsWbOwbt06DBo0CH/7298QFxeHr776Ct9++y2SkpKwaNEiTJw4sUH6olgFKTs7G3a7XS7jlQsODkZGRka1r8nIyLhm+6ysLBQUFGD+/PmIj4/Ht99+i0GDBmHw4MH44Ycf5HPo9foq0xCv9b4AkJSUJJdQTSaTUwKuTxyDRES3HUGQbnMpsQnCdXX1scceg0ajwdq1a/HRRx/hySefhFB2jp07d2LAgAF44okn0KlTJ7Ro0QK//fZbrc/dpk0bnDt3Dunp6fK+ync2du3ahWbNmuGVV15BVFQUIiIicPbsWac2er0edrv9T9/r559/RmFhobxv586d0Gg0aN26da37fD3KP9+5c+fkfb/++ityc3PRtm1beV+rVq0wdepUfPvttxg8eDA+/PBD+ViTJk3w9NNP4/PPP8dzzz2H9957r0H6CqhgkHZ9Kk+1AwYMwNSpU9G5c2e89NJLeOihh7BixYobOvf06dORl5cnb1f/B65PHINERKReXl5eGDp0KKZPn4709HSMHj1aPhYREYHk5GTs2rULx48fx9///vfrmgAUGxuLVq1aYdSoUfj555+xY8cOvPLKK05tIiIikJaWhnXr1uHUqVN48803sXHjRqc24eHhOH36NA4fPozs7Gynux/lEhISYDQaMWrUKBw9ehTbtm3DxIkTMWLEiCqFiOtlt9tx+PBhp+348eOIjY1Fhw4dkJCQgIMHD2Lv3r0YOXIkevfujaioKBQXF2PChAnYvn07zp49i507d2Lfvn1o06YNAGDKlCnYunUrTp8+jYMHD2Lbtm3ysYagWEAKDAyEVqut8suTmZlZ48CykJCQa7YPDAyETqdzSqKAlFrL78+GhITAarUiNze31u8LAAaDAT4+Pk5bQ+Cz2IiI1G3s2LG4cuUK4uLinMYLzZgxA127dkVcXBz69OmDkJAQeXhHbWg0GmzcuBHFxcXo0aMH/va3v2HevHlObR555BFMnToVEyZMQOfOnbFr1y68+uqrTm2GDBmC+Ph49O3bF40aNap2qQEPDw9s3boVOTk56N69Ox599FH069fPaUxvXRUUFKBLly5O28MPPwxBEPDf//4Xfn5+uPfeexEbG4sWLVpg/fr1AACtVovLly9j5MiRaNWqFR577DE88MADmDNnDgApeI0fPx5t2rRBfHw8WrVqhbfffvuG+1sTQRRrOcexAURHR6NHjx546623AEgVoKZNm2LChAl46aWXqrQfOnQoioqK8OWXX8r7evbsiY4dO8oVop49e6Jly5b4+OOP5TaDBg2Cu7s71q5di7y8PPkXZsiQIQCAkydPIjIy8ppjkCozm80wmUzIy8ur17D0w2+XMOqDvWgb6oOvJ99Tb+clIlKDkpISnD59Gs2bN3eaXUxUn671e1bbv9+KTvNPTEzEqFGjEBUVhR49emDJkiUoLCzEmDFjAAAjR45E48aNkZSUBACYPHkyevfujUWLFqF///5Yt24d9u/fj5UrV8rnnDZtGoYOHYp7770Xffv2xZYtW/Dll19i+/btAACTyYSxY8ciMTER/v7+8PHxwcSJExETE1PrcNSQOAaJiIhIeYoGpKFDh+LSpUuYOXMmMjIy0LlzZ2zZskW+/5mWlgaNpuIuYM+ePbF27VrMmDEDL7/8MiIiIrBp0yZ5DSRAqhatWLECSUlJmDRpElq3bo3//Oc/uPvuu+U2//rXv6DRaDBkyBBYLBbExcU1aJnuenAWGxERkfIUvcV2M2uoW2z7z+Tg0RWpCA/wwPZpfevtvEREasBbbOQK9XGL7ZaaxXYr4Cw2IiIi5TEgqYyu7JYixyAR0a2MNy+oIdXH7xcDksqwgkREt7LylZmLiooU7gndysp/vyqvBH49FB2kTVVxHSQiupVptVr4+vrKz/Py8PCQV6ImulGiKKKoqAhZWVnw9fV1eo7c9WJAUhk+rJaIbnXli/LW9aGnRH/G19f3mos/1wYDkspwHSQiutUJgoDQ0FAEBQWhtLRU6e7QLcbNze2GKkflGJBUhusgEdHtQqvV1ssfMqKGwEHaKsNZbERERMpjQFIZzmIjIiJSHgOSypSPQRJFwMGQREREpAgGJJXRaiumu7KKREREpAwGJJUpryABHIdERESkFAYkldFqrq4gcSYbERGREhiQVKZ8FhvAChIREZFSGJBU5qoCEscgERERKYQBSWUEQeBq2kRERApjQFIhroVERESkLAYkFZIrSHYGJCIiIiUwIKkQn8dGRESkLAYkFdJp+Tw2IiIiJTEgqRDHIBERESmLAUmFOIuNiIhIWQxIKsQKEhERkbIYkFSoooLEQdpERERKYEBSIbmCxGn+REREimBAUqHy57FxDBIREZEyGJBUiGOQiIiIlMWApEI6LWexERERKYkBSYVYQSIiIlIWA5IKcRYbERGRshiQVIgVJCIiImUxIKkQZ7EREREpiwFJhbgOEhERkbIYkFSIz2IjIiJSFgOSCnEMEhERkbIYkFSoYh0kzmIjIiJSAgOSCmnLBmmzgkRERKQMBiQV4hgkIiIiZTEgqRDHIBERESlLFQFp+fLlCA8Ph9FoRHR0NPbu3XvN9hs2bEBkZCSMRiM6dOiAr7/+2un46NGjIQiC0xYfH+/UJjw8vEqb+fPn1/tnqwtWkIiIiJSleEBav349EhMTMWvWLBw8eBCdOnVCXFwcsrKyqm2/a9cuDB8+HGPHjsWhQ4cwcOBADBw4EEePHnVqFx8fj/T0dHn75JNPqpzrtddec2ozceLEBvmM14vrIBERESlL8YC0ePFiPPXUUxgzZgzatm2LFStWwMPDAx988EG17ZcuXYr4+HhMmzYNbdq0wdy5c9G1a1csW7bMqZ3BYEBISIi8+fn5VTmXt7e3UxtPT88G+YzXi89iIyIiUpaiAclqteLAgQOIjY2V92k0GsTGxiI1NbXa16Smpjq1B4C4uLgq7bdv346goCC0bt0azzzzDC5fvlzlXPPnz0dAQAC6dOmChQsXwmaz1dhXi8UCs9nstDUUzmIjIiJSlk7JN8/OzobdbkdwcLDT/uDgYJw4caLa12RkZFTbPiMjQ/45Pj4egwcPRvPmzXHq1Cm8/PLLeOCBB5CamgqtVgsAmDRpErp27Qp/f3/s2rUL06dPR3p6OhYvXlzt+yYlJWHOnDk38nFrrWIdJAYkIiIiJSgakBrKsGHD5O87dOiAjh07omXLlti+fTv69esHAEhMTJTbdOzYEXq9Hn//+9+RlJQEg8FQ5ZzTp093eo3ZbEaTJk0apP+cxUZERKQsRW+xBQYGQqvVIjMz02l/ZmYmQkJCqn1NSEjIdbUHgBYtWiAwMBB//PFHjW2io6Nhs9lw5syZao8bDAb4+Pg4bQ2Fs9iIiIiUpWhA0uv16NatG1JSUuR9DocDKSkpiImJqfY1MTExTu0BIDk5ucb2AHD+/HlcvnwZoaGhNbY5fPgwNBoNgoKCrvNT1L+KChIHaRMRESlB8VtsiYmJGDVqFKKiotCjRw8sWbIEhYWFGDNmDABg5MiRaNy4MZKSkgAAkydPRu/evbFo0SL0798f69atw/79+7Fy5UoAQEFBAebMmYMhQ4YgJCQEp06dwgsvvIA777wTcXFxAKSB3nv27EHfvn3h7e2N1NRUTJ06FU888US1s91cjRUkIiIiZSkekIYOHYpLly5h5syZyMjIQOfOnbFlyxZ5IHZaWho0mopCV8+ePbF27VrMmDEDL7/8MiIiIrBp0ya0b98eAKDVanHkyBGsXr0aubm5CAsLw/3334+5c+fKY4sMBgPWrVuH2bNnw2KxoHnz5pg6darTGCMlybPYuA4SERGRIgRRFPlXuA7MZjNMJhPy8vLqfTzSez/+D/O+Po7BXRpj8dDO9XpuIiKi21lt/34rvlAkVcVZbERERMpiQFIhLccgERERKYoBSYU4i42IiEhZDEgqxFlsREREymJAUiGOQSIiIlIWA5IK8VlsREREymJAUiGug0RERKQsBiQV4hgkIiIiZTEgqRBnsRERESmLAUmFWEEiIiJSFgOSCnEWGxERkbIYkFRIVzZImxUkIiIiZTAgqRArSERERMpiQFIhroNERESkLAYkFeIsNiIiImUxIKmQPIuNC0USEREpggFJhTgGiYiISFkMSCrEWWxERETKYkBSIVaQiIiIlMWApEJcSZuIiEhZDEgqpGVAIiIiUhQDkgpxHSQiIiJlMSCpENdBIiIiUhYDkgqVz2JziICDVSQiIiKXY0BSofIKEgDYRQYkIiIiV2NAUiHd1QGJFSQiIiKXY0BSoasrSFwLiYiIyPUYkFTIqYLE57ERERG5HAOSCjlXkDiTjYiIyNUYkFRIEAQuFklERKQgBiSV4vPYiIiIlMOApFJ8HhsREZFyGJBUihUkIiIi5TAgqVRFBYmDtImIiFyNAUmltGWPG2EFiYiIyPUYkFSqvIJk4zpIRERELseApFKc5k9ERKQcBiSV0mk5SJuIiEgpDEgqxQoSERGRclQRkJYvX47w8HAYjUZER0dj796912y/YcMGREZGwmg0okOHDvj666+djo8ePRqCIDht8fHxTm1ycnKQkJAAHx8f+Pr6YuzYsSgoKKj3z1ZX8hgkzmIjIiJyOcUD0vr165GYmIhZs2bh4MGD6NSpE+Li4pCVlVVt+127dmH48OEYO3YsDh06hIEDB2LgwIE4evSoU7v4+Hikp6fL2yeffOJ0PCEhAceOHUNycjI2b96MH3/8EePGjWuwz3m9ymexsYJERETkeoIoior+BY6Ojkb37t2xbNkyAIDD4UCTJk0wceJEvPTSS1XaDx06FIWFhdi8ebO876677kLnzp2xYsUKAFIFKTc3F5s2bar2PY8fP462bdti3759iIqKAgBs2bIFDz74IM6fP4+wsLA/7bfZbIbJZEJeXh58fHyu92P/qYff+gm/XMjDh2O6o2/roHo/PxER0e2otn+/Fa0gWa1WHDhwALGxsfI+jUaD2NhYpKamVvua1NRUp/YAEBcXV6X99u3bERQUhNatW+OZZ57B5cuXnc7h6+srhyMAiI2NhUajwZ49e6p9X4vFArPZ7LQ1JHkMEqf5ExERuZyiASk7Oxt2ux3BwcFO+4ODg5GRkVHtazIyMv60fXx8PD766COkpKRgwYIF+OGHH/DAAw/AbrfL5wgKcq7K6HQ6+Pv71/i+SUlJMJlM8takSZPr/rzXQ8dHjRARESlGp3QHGsKwYcPk7zt06ICOHTuiZcuW2L59O/r161enc06fPh2JiYnyz2azuUFDEmexERERKUfRClJgYCC0Wi0yMzOd9mdmZiIkJKTa14SEhFxXewBo0aIFAgMD8ccff8jnqDwI3GazIScnp8bzGAwG+Pj4OG0NqWIdJM5iIyIicjVFA5Jer0e3bt2QkpIi73M4HEhJSUFMTEy1r4mJiXFqDwDJyck1tgeA8+fP4/LlywgNDZXPkZubiwMHDshtvv/+ezgcDkRHR9/IR6o3nMVGRESkHMWn+ScmJuK9997D6tWrcfz4cTzzzDMoLCzEmDFjAAAjR47E9OnT5faTJ0/Gli1bsGjRIpw4cQKzZ8/G/v37MWHCBABAQUEBpk2bht27d+PMmTNISUnBgAEDcOeddyIuLg4A0KZNG8THx+Opp57C3r17sXPnTkyYMAHDhg2r1Qw2V+AYJCIiIuUoPgZp6NChuHTpEmbOnImMjAx07twZW7ZskQdip6WlQaOpyHE9e/bE2rVrMWPGDLz88suIiIjApk2b0L59ewCAVqvFkSNHsHr1auTm5iIsLAz3338/5s6dC4PBIJ9nzZo1mDBhAvr16weNRoMhQ4bgzTffdO2HvwaOQSIiIlKO4usg3awaeh2kZ/7vAL45moG5A9tjxF3N6v38REREt6ObYh0kqlnFOkgcpE1ERORqDEgqxTFIREREymFAUinOYiMiIlIOA5JKsYJERESkHAYkldJqOYuNiIhIKQxIKsUKEhERkXIYkFSqYh0kzmIjIiJyNQYklWIFiYiISDkMSColz2KzMyARERG5GgOSSrGCREREpBwGJJXis9iIiIiUw4CkUqwgERERKYcBSaU0nMVGRESkGAYklWIFiYiISDkMSCrFMUhERETKYUBSKVaQiIiIlMOApFJaLddBIiIiUgoDkkqxgkRERKQcBiSV4rPYiIiIlMOApFKsIBERESmHAUmlOIuNiIhIOQxIKqUre1gtK0hERESux4CkUqwgERERKYcBSaU4BomIiEg5dQpI586dw/nz5+Wf9+7diylTpmDlypX11rHbnVbLWWxERERKqVNAevzxx7Ft2zYAQEZGBv7yl79g7969eOWVV/Daa6/VawdvV3IFiQtFEhERuVydAtLRo0fRo0cPAMCnn36K9u3bY9euXVizZg1WrVpVn/27bXEMEhERkXLqFJBKS0thMBgAAN999x0eeeQRAEBkZCTS09Prr3e3sfJZbAxIRERErlengNSuXTusWLECO3bsQHJyMuLj4wEAFy9eREBAQL128Hal5SBtIiIixdQpIC1YsADvvvsu+vTpg+HDh6NTp04AgC+++EK+9UY3RsdbbERERIrR1eVFffr0QXZ2NsxmM/z8/OT948aNg4eHR7117nZWUUHiLDYiIiJXq1MFqbi4GBaLRQ5HZ8+exZIlS3Dy5EkEBQXVawdvVzotK0hERERKqVNAGjBgAD766CMAQG5uLqKjo7Fo0SIMHDgQ77zzTr128HbFhSKJiIiUU6eAdPDgQdxzzz0AgM8++wzBwcE4e/YsPvroI7z55pv12sHblbZ8FhvXQSIiInK5OgWkoqIieHt7AwC+/fZbDB48GBqNBnfddRfOnj1brx28XbGCREREpJw6BaQ777wTmzZtwrlz57B161bcf//9AICsrCz4+PjUawdvV1wokoiISDl1CkgzZ87E888/j/DwcPTo0QMxMTEApGpSly5d6rWDtyt5mr/IgERERORqdZrm/+ijj+Luu+9Genq6vAYSAPTr1w+DBg2qt87dzq6uIImiCEEQFO4RERHR7aNOFSQACAkJQZcuXXDx4kWcP38eANCjRw9ERkZe97mWL1+O8PBwGI1GREdHY+/evddsv2HDBkRGRsJoNKJDhw74+uuva2z79NNPQxAELFmyxGl/eHg4BEFw2ubPn3/dfW8o5Y8aAXibjYiIyNXqFJAcDgdee+01mEwmNGvWDM2aNYOvry/mzp0Lx3UubLh+/XokJiZi1qxZOHjwIDp16oS4uDhkZWVV237Xrl0YPnw4xo4di0OHDmHgwIEYOHAgjh49WqXtxo0bsXv3boSFhVV7rtdeew3p6enyNnHixOvqe0PSaisqRhyoTURE5Fp1CkivvPIKli1bhvnz5+PQoUM4dOgQXn/9dbz11lt49dVXr+tcixcvxlNPPYUxY8agbdu2WLFiBTw8PPDBBx9U237p0qWIj4/HtGnT0KZNG8ydOxddu3bFsmXLnNpduHABEydOxJo1a+Dm5lbtuby9vRESEiJvnp6e19X3hlQ+BglgBYmIiMjV6hSQVq9ejX//+9945pln0LFjR3Ts2BHPPvss3nvvPaxatarW57FarThw4ABiY2MrOqTRIDY2FqmpqdW+JjU11ak9AMTFxTm1dzgcGDFiBKZNm4Z27drV+P7z589HQEAAunTpgoULF8Jms9W67w1Nq2EFiYiISCl1GqSdk5NT7VijyMhI5OTk1Po82dnZsNvtCA4OdtofHByMEydOVPuajIyMattnZGTIPy9YsAA6nQ6TJk2q8b0nTZqErl27wt/fH7t27cL06dORnp6OxYsXV9veYrHAYrHIP5vN5j/9fDdCK7CCREREpJQ6BaROnTph2bJlVVbNXrZsGTp27FgvHaurAwcOYOnSpTh48OA1Z34lJibK33fs2BF6vR5///vfkZSUBIPBUKV9UlIS5syZ0yB9ro5GI0AjAA6RD6wlIiJytToFpDfeeAP9+/fHd999J6+BlJqainPnzl1zRlllgYGB0Gq1yMzMdNqfmZmJkJCQal8TEhJyzfY7duxAVlYWmjZtKh+32+147rnnsGTJEpw5c6ba80ZHR8Nms+HMmTNo3bp1lePTp093ClVmsxlNmjSp1eesK51GA6vdwQoSERGRi9VpDFLv3r3x22+/YdCgQcjNzUVubi4GDx6MY8eO4eOPP671efR6Pbp164aUlBR5n8PhQEpKihy8KouJiXFqDwDJycly+xEjRuDIkSM4fPiwvIWFhWHatGnYunVrjX05fPgwNBoNgoKCqj1uMBjg4+PjtDW08nFINj6PjYiIyKXqVEECgLCwMMybN89p388//4z3338fK1eurPV5EhMTMWrUKERFRaFHjx5YsmQJCgsLMWbMGADAyJEj0bhxYyQlJQEAJk+ejN69e2PRokXo378/1q1bh/3798vvGRAQgICAAKf3cHNzQ0hIiFwZSk1NxZ49e9C3b194e3sjNTUVU6dOxRNPPAE/P7+6XpJ6p+PjRoiIiBRR54BUX4YOHYpLly5h5syZyMjIQOfOnbFlyxZ5IHZaWho0Vy2a2LNnT6xduxYzZszAyy+/jIiICGzatAnt27ev9XsaDAasW7cOs2fPhsViQfPmzTF16lSnW2hqUL4WEmexERERuZYgivX3sK+ff/4ZXbt2hd1ur69TqpbZbIbJZEJeXl6D3W6L+kcysgus2DrlXrQO8W6Q9yAiIrqd1Pbvd50fNUINTx6DxFlsRERELnVdt9gGDx58zeO5ubk30heqpPx5bByDRERE5FrXFZBMJtOfHh85cuQNdYgqVFSQGJCIiIhc6boC0ocffthQ/aBqcBYbERGRMjgGScW4DhIREZEyGJBUTMsKEhERkSIYkFRMp+UsNiIiIiUwIKmYlrPYiIiIFMGApGI6zmIjIiJSBAOSinEMEhERkTIYkFSMFSQiIiJlMCCpWEUFiYO0iYiIXIkBScV0XAeJiIhIEQxIKsZZbERERMpgQFIxjkEiIiJSBgOSimm1nMVGRESkBAYkFWMFiYiISBkMSCrGWWxERETKYEBSMVaQiIiIlMGApGLyLDZO8yciInIpBiQVYwWJiIhIGQxIKsZnsRERESmDAUnFWEEiIiJSBgOSinEWGxERkTIYkFRMywoSERGRIhiQVEzHMUhERESKYEBSsfJp/qwgERERuRYDkorpyp/FxnWQiIiIXIoBScU4BomIiEgZDEgqpuMsNiIiIkUwIKkYK0hERETKYEBSMc5iIyIiUgYDkopxFhsREZEyGJBUjBUkIiIiZTAgqRjHIBERESmDAUnF5HWQOIuNiIjIpRiQVEyuIHGhSCIiIpdiQFIxjkEiIiJSBgOSinEWGxERkTJUEZCWL1+O8PBwGI1GREdHY+/evddsv2HDBkRGRsJoNKJDhw74+uuva2z79NNPQxAELFmyxGl/Tk4OEhIS4OPjA19fX4wdOxYFBQX18XHqDStIREREylA8IK1fvx6JiYmYNWsWDh48iE6dOiEuLg5ZWVnVtt+1axeGDx+OsWPH4tChQxg4cCAGDhyIo0ePVmm7ceNG7N69G2FhYVWOJSQk4NixY0hOTsbmzZvx448/Yty4cfX++W4EZ7EREREpQ/GAtHjxYjz11FMYM2YM2rZtixUrVsDDwwMffPBBte2XLl2K+Ph4TJs2DW3atMHcuXPRtWtXLFu2zKndhQsXMHHiRKxZswZubm5Ox44fP44tW7bg3//+N6Kjo3H33Xfjrbfewrp163Dx4sUG+6zXi89iIyIiUoaiAclqteLAgQOIjY2V92k0GsTGxiI1NbXa16Smpjq1B4C4uDin9g6HAyNGjMC0adPQrl27as/h6+uLqKgoeV9sbCw0Gg327Nlzox+r3rCCREREpAydkm+enZ0Nu92O4OBgp/3BwcE4ceJEta/JyMiotn1GRob884IFC6DT6TBp0qQazxEUFOS0T6fTwd/f3+k8V7NYLLBYLPLPZrO55g9WTyrWQWJAIiIiciXFb7HVtwMHDmDp0qVYtWoVBEGot/MmJSXBZDLJW5MmTert3DWRZ7FxHSQiIiKXUjQgBQYGQqvVIjMz02l/ZmYmQkJCqn1NSEjINdvv2LEDWVlZaNq0KXQ6HXQ6Hc6ePYvnnnsO4eHh8jkqDwK32WzIycmp8X2nT5+OvLw8eTt37lxdPvJ14Sw2IiIiZSgakPR6Pbp164aUlBR5n8PhQEpKCmJiYqp9TUxMjFN7AEhOTpbbjxgxAkeOHMHhw4flLSwsDNOmTcPWrVvlc+Tm5uLAgQPyOb7//ns4HA5ER0dX+74GgwE+Pj5OW0PjGCQiIiJlKDoGCQASExMxatQoREVFoUePHliyZAkKCwsxZswYAMDIkSPRuHFjJCUlAQAmT56M3r17Y9GiRejfvz/WrVuH/fv3Y+XKlQCAgIAABAQEOL2Hm5sbQkJC0Lp1awBAmzZtEB8fj6eeegorVqxAaWkpJkyYgGHDhlW7JIBSOIuNiIhIGYoHpKFDh+LSpUuYOXMmMjIy0LlzZ2zZskUeiJ2WlgaNpqLQ1bNnT6xduxYzZszAyy+/jIiICGzatAnt27e/rvdds2YNJkyYgH79+kGj0WDIkCF488036/Wz3ShWkIiIiJQhiKLIv751YDabYTKZkJeX12C329IuF+Hehdvgodfi19fiG+Q9iIiIbie1/ft9y81iu5VotawgERERKYEBScU4i42IiEgZDEgqpr0qIPFOKBERkeswIKlYeQUJYBWJiIjIlRiQVEx7dUBiBYmIiMhlGJBUTHfV8gasIBEREbkOA5KKXV1B4kw2IiIi12FAUjGnMUh8YC0REZHLMCCpmEYjQCjLSKwgERERuQ4DkspxLSQiIiLXY0BSuYrnsfGBtURERK7CgKRy5TPZWEEiIiJyHQYklauoIDEgERERuQoDkspxDBIREZHrMSCpnFxB4jR/IiIil2FAUjlWkIiIiFyPAUnltFrOYiMiInI1BiSV4yw2IiIi12NAUjnOYiMiInI9BiSV4xgkIiIi12NAUjlWkIiIiFyPAUnlKipIHKRNRETkKgxIKsd1kIiIiFyPAUnlOIuNiIjI9RiQVI5jkIiIiFyPAUnldFrOYiMiInI1BiSVYwWJiIjI9RiQVI6z2IiIiFyPAUnlWEEiIiJyPQYkleMsNiIiItdjQFI5roNERETkegxIKsdnsREREbkeA5LKcQwSERGR6zEgqVzFOkicxUZEROQqDEhqc/xLYPsCIPt3AIBGYAWJiIjI1XRKd4Aq2bsSOP0j4NcMCIzgGCQiIiIFsIKkNqYm0te8cwAAbdk0f1aQiIiIXIcBSW3KA1KuFJD4LDYiIiLXY0BSG9Md0te88wC4DhIREZESVBGQli9fjvDwcBiNRkRHR2Pv3r3XbL9hwwZERkbCaDSiQ4cO+Prrr52Oz549G5GRkfD09ISfnx9iY2OxZ88epzbh4eEQBMFpmz9/fr1/tuvm63yLjc9iIyIicj3FA9L69euRmJiIWbNm4eDBg+jUqRPi4uKQlZVVbftdu3Zh+PDhGDt2LA4dOoSBAwdi4MCBOHr0qNymVatWWLZsGX755Rf89NNPCA8Px/33349Lly45neu1115Denq6vE2cOLFBP2utyGOQzgOiyHWQiIiIFKB4QFq8eDGeeuopjBkzBm3btsWKFSvg4eGBDz74oNr2S5cuRXx8PKZNm4Y2bdpg7ty56Nq1K5YtWya3efzxxxEbG4sWLVqgXbt2WLx4McxmM44cOeJ0Lm9vb4SEhMibp6dng37WWvFpLH0tLQKKcjiLjYiISAGKBiSr1YoDBw4gNjZW3qfRaBAbG4vU1NRqX5OamurUHgDi4uJqbG+1WrFy5UqYTCZ06tTJ6dj8+fMREBCALl26YOHChbDZbDf4ieqBmxHwDJK+zzvHWWxEREQKUHQdpOzsbNjtdgQHBzvtDw4OxokTJ6p9TUZGRrXtMzIynPZt3rwZw4YNQ1FREUJDQ5GcnIzAwED5+KRJk9C1a1f4+/tj165dmD59OtLT07F48eJq39discBiscg/m83m6/qs18W3CVCYBeSdg07TDgArSERERK50yy4U2bdvXxw+fBjZ2dl477338Nhjj2HPnj0ICpKqM4mJiXLbjh07Qq/X4+9//zuSkpJgMBiqnC8pKQlz5sxxTedNdwAXDgB556HVtAfAChIREZErKXqLLTAwEFqtFpmZmU77MzMzERISUu1rQkJCatXe09MTd955J+666y68//770Ol0eP/992vsS3R0NGw2G86cOVPt8enTpyMvL0/ezp07V4tPWEdXrYXEZ7ERERG5nqIBSa/Xo1u3bkhJSZH3ORwOpKSkICYmptrXxMTEOLUHgOTk5BrbX33eq2+RVXb48GFoNBq5wlSZwWCAj4+P09ZgrlpNm+sgERERuZ7it9gSExMxatQoREVFoUePHliyZAkKCwsxZswYAMDIkSPRuHFjJCUlAQAmT56M3r17Y9GiRejfvz/WrVuH/fv3Y+XKlQCAwsJCzJs3D4888ghCQ0ORnZ2N5cuX48KFC/jrX/8KQBrovWfPHvTt2xfe3t5ITU3F1KlT8cQTT8DPz0+ZC3G1q9ZC4iw2IiIi11M8IA0dOhSXLl3CzJkzkZGRgc6dO2PLli3yQOy0tDRoNBWFrp49e2Lt2rWYMWMGXn75ZURERGDTpk1o314aq6PVanHixAmsXr0a2dnZCAgIQPfu3bFjxw60aycNeDYYDFi3bh1mz54Ni8WC5s2bY+rUqU7jkhR11WranMVGRETkeoIoivzLWwdmsxkmkwl5eXn1f7utKAd4ozkA4IuHDmLSZydw952B+L+/Rdfv+xAREd1mavv3W/GFIqka7n6Am7RopVeJtHyBjYO0iYiIXIYBSY0EQR6H5FWSDoBjkIiIiFyJAUmtysYheZYFJI5BIiIich0GJLUqm+rvUcwKEhERkasxIKlVWQXJvaisgsR1kIiIiFyGAUmtfJsCANyLLgBgBYmIiMiVGJDUqqyCZCgsH4PEWWxERESuwoCkVmVjkPRF6RDgYAWJiIjIhRiQ1Mo7FBC00DhK0Qh5nMVGRETkQgxIaqXVAT5hAIA7hEusIBEREbkQA5KalY1DChMus4JERETkQgxIalY2DqmxkI1iqx18bB4REZFrMCCpWVkFqYn2MgosNpy6VKhwh4iIiG4PDEhqVvY8tjbueQCA/WdylOwNERHRbYMBSc3KbrE10V4GAOw7c0XJ3hAREd02GJDUrCwg+ZVmAgD2n2UFiYiIyBUYkNSsbAySW2k+fIQinL1chKz8EoU7RUREdOtjQFIzgxfg7gcA6BlYDAA4wNtsREREDY4BSe3Kqki9AqXKEcchERERNTwGJLUzNQUAdPQ2A+A4JCIiIldgQFK7sgpSC71UOTp20YxCi03JHhEREd3yGJDUrmwtJO+SdISZjLA7RBw+l6tsn4iIiG5xDEhqV1ZBQt55RIX7AwD2cxwSERFRg2JAUruyMUjI/h3RTb0AcBwSERFRQ2NAUrvgdoBXMFCcg35F3wAADp69ApvdoXDHiIiIbl0MSGrnZgR6vwAACD78JoIMNhRa7TiRka9wx4iIiG5dDEg3g66jAL/mEAov4UXfFADAPj64loiIqMEwIN0MtG7AfTMAAA8XfAZ/mDlQm4iIqAExIN0s2g0GQjpCby/Es7r/Yv/ZHIiiqHSviIiIbkkMSDcLjQaInQUAGKlNhs58HuevFCvcKSIiolsTA9LNpGU/IPwe6AUbpuj+g+9PZCndIyIiolsSA9LNRBCA2DkAgMHaHdj69efY/b/LCneKiIjo1sOAdLO5oxsckY9AK4j4WPsafls9Eb+eTVe6V0RERLcUBqSbkGbAW7C3fwxaQcRI4SuYPrwXmYe+UrpbREREtwwGpJuRuy+0j76Hor+uQ6amERojC8H/fRwlax4Hfv0vYC1UuodEREQ3NUHkXPE6MZvNMJlMyMvLg4+Pj2L9uHQ5Gz+8MxmDS7+CRpD+U4o6dwgRsUCbR4CmMdIDbwVBsT4SERGpRW3/fjMg1ZFaAhIAnL1ciFfe+QT3lnyPBzR70URzybmBuz8Q2knaAlsBHv6Au5+0390P8AxkgCIiotsCA1IDU1NAAgBzSSk+238eq3edhteV44jX7sV9mkNorTkPHezXfrGbJxAYIYWnwFZAQAvAOwzwCQW8QwGdoaKtKAL2UgCi8/6riSKQdx4wXwSC2gBG5a8PERERwIDU4NQWkMrZHSK2n8zCql1nsOP3bBhgRSvhPNprTqOD5gxaG3IQqCuGCQXwsOfDrdQMAX/yK+ARAAgaoLRY2sSywOUVDPiFA77NAL9mQPEVIPMYkPkrYMmT2ggaqXLVrJe0Ne4qvY4VKyIiUsBNFZCWL1+OhQsXIiMjA506dcJbb72FHj161Nh+w4YNePXVV3HmzBlERERgwYIFePDBB+Xjs2fPxrp163Du3Dno9Xp069YN8+bNQ3R0tNwmJycHEydOxJdffgmNRoMhQ4Zg6dKl8PLyqlWf1RqQrpaRV4I9py8j9dRl7P7fZZy5XFSljQ42NBWy0NXjEjoZM9FKm44wMQMm22V4WrKgdVjr9uYaNylYFWRUPebmKQUr/+ZSuNLqANEhVZ5EB6AzSpUr7xDAJ0z66hkE6PR16wsREVGZmyYgrV+/HiNHjsSKFSsQHR2NJUuWYMOGDTh58iSCgoKqtN+1axfuvfdeJCUl4aGHHsLatWuxYMECHDx4EO3btwcArF27FkFBQWjRogWKi4vxr3/9Cxs2bMAff/yBRo0aAQAeeOABpKen491330VpaSnGjBmD7t27Y+3atbXq980QkCpLzyvGsQtm/J5VgD+yCvDHpQKcyipAgcVWwytE+KIAwcIViBAguBnh7uEFD08vBHroEK67jCZCFsIcmQi0Z0Bn9IatUXtoQtvDIywSvl6e8ChOh5CWCpz5CTi7C8g5JYWgujCapKDkFSSNndIZAK1B+qozAAYfwN1XOmb0ldobvAC9F6D3BNw8pO81nLxJRHS7umkCUnR0NLp3745ly5YBABwOB5o0aYKJEyfipZdeqtJ+6NChKCwsxObNm+V9d911Fzp37owVK1ZU+x7lF+O7775Dv379cPz4cbRt2xb79u1DVFQUAGDLli148MEHcf78eYSFhf1pv2/GgFQdURSRW1SKc1eKcP5KMc7lFOFibjGy8i3Iyrcg01yCLLMFVnvdQo1WI8DHqIO30Q0+7jr46oFwbTaaCZloLKajkT0beh3gptPCTaeDXqeDO4rhbsmGoTgLuqJMCPkZEByl9fOBBY0Untz9yoKUCdDoAI1WOqbRSkHK3R/w8Ktop9WXtXOT2ui9pMqWdwigdZPOXZIHnNkJnP4BOP0jYCkA2jwMdBoGhHTgbUUiIhWo7d9vnQv7VIXVasWBAwcwffp0eZ9Go0FsbCxSU1OrfU1qaioSExOd9sXFxWHTpk01vsfKlSthMpnQqVMn+Ry+vr5yOAKA2NhYaDQa7NmzB4MGDapyHovFAovFIv9sNptr/TnVTBAE+Hnq4eepR8c7fKttI4oi8i025BRYcbnQgssFVuQUWpFbXIorRVbkFpZ9LS5FbpEVuUWlyC0qhdXugN0h4kpRKa4UVQScn6AH0KRs+3NuWiBUX4I73AoQ5paPYG0+ArVF8NTY4aGzw1Njg7vGBi+xEJ6OArjb82G0maG35UNnL4LWVgRNaSEE0SFVr4pzpK1eCIBnIylEXf69anVs93JpC2oHdBoKNIqUXiNoAAHS7USfMMCnsfOg96IcIOMIkPGLNOA9sBUQ1lk6j5uxnvpOREQ1UTQgZWdnw263Izg42Gl/cHAwTpw4Ue1rMjIyqm2fkeE81mXz5s0YNmwYioqKEBoaiuTkZAQGBsrnqHz7TqfTwd/fv8p5yiUlJWHOnDnX9fluFYIgwMfoBh+jG8IDPWv1GlEUUVxqh7nYhvySUphLSpFXXIr8EhsKLDYUlNiQXyIdy7dI3xeU2JBvKYW52AZzSSnMxaVwiECpHUgrNiKt2AggsI6fQoQRVnijCMFuRQh2K0aQrgj+OgvctSLcdYC7DjBqAW+NBT4ogLfDDE+7Ge72fLgJdujggBZ2aGGHzpoPTWGmVNkqzJI2APBvCbToDTTvLVWdjqwHTn4DZB0Dkmdeu4ueQVJYKswGzOerb6PRSTMDG7UBfJtIa1yZyr56BUvVMd5CJCK6YYoGpIbUt29fHD58GNnZ2Xjvvffw2GOPYc+ePdWOa6qN6dOnO1WuzGYzmjSpXQXkdiQIAjz0OnjodQgx1a3iIYoiCq125BWXosgiBasiqx0FFhsKy7b8sq8FJTYUWOwosla0Kyx7TXkgK3EYUAIDLpX64Wg93LET4ECgkI9m+nw01hcg29gMFrcwmLLd4FPoBi+DDkbPF+HbbSLa5n6PVtkpcLfnQytA2jQitPYSuBWkQ7AVOwctAPBrDoR2lAJQ1nEg/TBQdFmqKmX8UkOntNK6VuVVLaNJGptl9JG+uhmlcVtavTToXaOTlm1w2Co2j0DAt6m0+YRJtxSJiG4zigakwMBAaLVaZGZmOu3PzMxESEhIta8JCQmpVXtPT0/ceeeduPPOO3HXXXchIiIC77//PqZPn46QkBBkZWU5tbfZbMjJyanxfQ0GAwyGGtb9oQYhCAK8DDp4GW7811QURVhsDjk4FVntKLRWBK0CS0WgKrLaUFgWtgrLg1ZZxavAIlW3Ciw2iKIGl0QTLllM2G8BkA8AV2roQbuyrdrewRcFaKK9jOZuubDpTbhobAmNmw+8CtzgVaqF0aCF8U4NgsRsNLOcRHDpRfjbMuFrzYSnJR3uRenQWc3SEgwFmdJWHzQ6wCsE0HtItwPdPAA3d8DgXTY+y1f6avAum4UoSn1w2KWB8eXjtLxCpNCmrea/pShKj8cpuiyN4/IJk0IeEZGCFA1I5VPwU1JSMHDgQADSIO2UlBRMmDCh2tfExMQgJSUFU6ZMkfclJycjJibmmu/lcDjkMUQxMTHIzc3FgQMH0K1bNwDA999/D4fD4bQUAN06BEGA0U0Lo5sW/p43vlxA+S3EgrLQVGixy7cFpa9SdctSakdxqR0lpXYUlzpQaLHBXHarUbr1aEOh1YZc0Ru5dm/8YgdQAsDsAJBbw7s3LducucEGf5gRKJgRKOQhQFMIf10JAnQl8NUUw6QpgYfGBneNHUaNDQbBBr0gQqNzg1anh9ZNDzedFu7Wy9AXnIdb/gXpFmJNt/vqQme8avahEXCUSsHIXmk5CXf/soVLI6QlIcrDmNFX+mowlVXFvKXzKDUA3maVBuWX5AERf5EqdkR0S1D8FltiYiJGjRqFqKgo9OjRA0uWLEFhYSHGjBkDABg5ciQaN26MpKQkAMDkyZPRu3dvLFq0CP3798e6deuwf/9+rFy5EgBQWFiIefPm4ZFHHkFoaCiys7OxfPlyXLhwAX/9618BAG3atEF8fDyeeuoprFixAqWlpZgwYQKGDRtWqxlsRFffQqzbTdsKDocUtirfMsyXbx3aygKWHSWlDpSUty0bs5VfIoWuAosdZosBmaX+gAjAAaCmFRxqQQMHgnAFwcIVeGlt8HOzwUdng0lXCl9tCfyEQvgKBfBBIbzEImi1Wmi1Omh10lejowjulkswllyCviQbgmgHbCXSVh2tQQo9hdnSIPpzu6XtTzuqkypbgFSNQlkly829LFSZypZ98Cm7vVg2G1HrBliLpNuaBVnS+5bkSm09A6XlJDyDpBXl/cLLtubSo3r+t116MPSJrysWRdW5A20fATonAOH3XHssmN0mVfnKQx4RqY7iAWno0KG4dOkSZs6ciYyMDHTu3BlbtmyRB2KnpaVBc9U/ND179sTatWsxY8YMvPzyy4iIiMCmTZvkNZC0Wi1OnDiB1atXIzs7GwEBAejevTt27NiBdu0qbnGsWbMGEyZMQL9+/eSFIt98803XfngiABqNAE+DDp6GGw9bgLSaesXtQylMFVorvq8IXhUD4vOKK7Yii3T7schqR4YjABligBS0bjBs+aIARlhhEEphQCkMsELQaGHR+8Gq94PO4AlPow5+vjY012SimXged9jPI8CWCQ97ATwc+TDa8mGwmaG3FUJnK5BWgXfYAEs1s0pLC4Gi7OvvrLXg+qpmXiFS0Mn+TRqUf2Q9YGoqDabX6aXxXlqD1M+882WP4blQsSK9zx1AUKQ0w9G/RcWyESirimn1UtjTe1Tc4tTqK5ae0LpJbe1WaTyZ3Sq9l96rLByabu1FVotyyq4LZ3dS/VJ8HaSb1a2yDhJRTURRhNXuQJHFjqJSO4osFWOyiqzSGK1iq13+vsBiR4Gl/PahdKzi9qLUrsQqncvuuPF/dgQ44AELvFAMD8FSVjTTyA/OMWlL0UhXjEBdMQK1RdItRq0dRq0Io8YBd60dos6IYjd/lBgCYDEGwqb3gQlFMDmuwMeeCy9bDrwsmfAqOg+PwnMwFFyAINpg8wxFaeuHILQbCH14jPR/4i4cAA79H3D0P9UHtiofQFsRkhqam4dUGSt/UHX5V61Buj0paKStXPnK9hDLQpi+YmC/oAFKzNJtxZJc6aubuxTu/JpLK+T73CFdg8JLFZslH7BZykKc5aoQ5yuFOHdfqZ+Vb5eWP9Ko/BFFoiiF0RObgRNfSdddawCaxQAt+gAt+gIhHWuu4FkKgPN7gUu/AQF3AmFdAM+Aul3Xkjzg3D4pIAe2kj4Dqd5Ns1DkzYoBiahuyoNXidUhV7rKx3HJMxStNvn7Iqt0a9FSaofF5kBxqV0KZqV2FJdVusrDWHGpHQ35L5oWdvjDjGyYIKLiD7BBp4GbVgM3rQBPTSl6CUfgLxTAXWODUWOHUbBBo9HArA9GvjEERcZQWN0bwUcoRmNbGkKsZxFUfBq+1nRoIEIrSH/fNQC0sMHNXgytvQQ6exE0thJoRBsER2nZZpNCg84ghxlBo5UGvtcmqN0sdO5SULJbpRX5r8VgAvzDy5bAaAKYGgPmdCBtF5B+pGow9W0KhHUtCzl+zmPeyico6AxSH/LOA6dSgD9SgPP7nM/lGSSdw795RQgtHzcnOqT/JtZCKaSJdulRSwF3AgEtpfYOB5CXBmSdAC6dkB74HRghhbjg9hVVMrtNCokZvwCX/5Be36SHFFC5IO2fYkBqYAxIROpz9WzF8iBVHp7KK16FVilYFVrtsJQ6UGp3oNThQKlNhNUuhbHiUqnaVWKzOwW08mpY+XgwNRIEQK/VwKDTwEMHBLhZEKArRoCmCL4ogK+QD18UwEfMh5vggE4QoRNEaDTS8hMaQQNBI0AQBAiCBjrY4YZS6ERp08IBu94HDoMPxLLqj8FeCM/CNLgXpME9/yzcijLhMJhgdw+E3SMQDo9GgMEbgs4AQaeHoDNCo9VCZyuCxpIHTUmuVI0qLYZ8axGQQkR+uhRKrl6EVauX1hqL7A+0flCq5PxvmzQ27PQOwJp/7YtkagoEt5MWd738x41dcL/mUmUs/+KNncfoK53HVlz98fI10DQ66YHgdkvVNp6NgCbRUjutXlqiQ6OTqpUoe9al6JBmmQJlEybKq4OGsrF5V43Ru/oh5bbiiv8+bkYpLLpdNbPVzb3sew/pv8flP4DLp6SveecB7+CyMFgWCN39gOJc6SHnxVek//52W0Ufy/vbdqD0MPR6xIDUwBiQiG5vDod4VYCyw2YXUWp3wGp3oLTs+1KbA5byr2VbcaldDlvl+6w2Byw2KbBZ7OU/O2C12WG1See02q7a7A6ntjc7jYCyCpwGOq0AnUaATiN9rxEEuMGGUGQjVMyEu1CKE4ZOcOi9YHTTwqDTQC9X8DQwau0ItabBtzQTftYMmKyZMJVmwqLzwUVTZ2T6doHVMwwGnVQBNNjyEZh/Ao3Mx+BlyYDRZobRlgd9qRmGUjO09hJoHBZo7FZo7SWwuXkhL6QnCu64F8VN+0DwawqNIACWAuhzf4c+9xT05nNwK82DzmqG1poHbUkuBI0WYvlzIfVeEARAk3sGQs7/IJgvVFwMrV6qQjVqLS15cekkcOFg1fF0ei/pEUb+LaVqUvrhqrNBbwUjNgIt76vXUzIgNTAGJCJSA1EUKwKZvSJMWWzSjMerb0+WXhXerHaHHOqu3m9ziLCVPSao1C7CIYqwOaSfy9tffe6SshBns0vtbGXt5Nc4RNjtIkodFee8eZX3vf5uYwkC4KO14k7tJdg0bkgXQiFqddAKArQaQarsAQgWLqON4xR0goiz+hbI1oVBp9NCp9FIVUNY0dz6B1pZj6GRPRNaOMo2O3SwQygfZ6bRQhCk4KkTrdCJNuhQCp3DKj0pQLRBI9qhhQ0aiLBpDHBo3WHXGeHQGqUnJDlKpM1ugdZhgc5eAq18G7gYdq07Cr3DUeQVjiLvcFg9w2C0ZMOr4DTc88/A3Xwa2tIC2A2+sBt84TD6ShVJrQGCoIFQNi5O0GigvXsyDI071Nv1BhiQGhwDEhFR3TgcUmCSq262isqb3VH+VTrmEKUQKJa9zu4QyypvFcteSIGvompX6ihb6gFSpBFFwOYQ5Upd+fuJYvlxqa2jLGzayoJiaXkbUTomhUVRDqCWUrt8HqBi+I/0iCQpeEphkX9m6+qjJ3vg3laN6vWcN8XDaomI6Paj0QgwaLSoh0XybwoOhxSuREhBSxQhV+Qsdrt869TuEGEXpRDocKDi+0pfbVdV+0rt0i1WKeyJZWGu/H1E2MvPU9a+vHJoszvk/jjEij7aHah4H4cUWCtXBe0OKVSW9+/qACkHWvGqc4sVr5crlXbn9varX+OoeJ1Wo9yg89vk15OIiEgZGo0ATY235dxq2E9K42O/iYiIiCphQCIiIiKqhAGJiIiIqBIGJCIiIqJKGJCIiIiIKmFAIiIiIqqEAYmIiIioEgYkIiIiokoYkIiIiIgqYUAiIiIiqoQBiYiIiKgSBiQiIiKiShiQiIiIiCphQCIiIiKqRKd0B25WoigCAMxms8I9ISIiotoq/7td/ne8JgxIdZSfnw8AaNKkicI9ISIiouuVn58Pk8lU43FB/LMIRdVyOBy4ePEivL29IQhCvZ3XbDajSZMmOHfuHHx8fOrtvFQVr7Vr8Xq7Dq+16/Bau059XWtRFJGfn4+wsDBoNDWPNGIFqY40Gg3uuOOOBju/j48P/8fmIrzWrsXr7Tq81q7Da+069XGtr1U5KsdB2kRERESVMCARERERVcKApDIGgwGzZs2CwWBQuiu3PF5r1+L1dh1ea9fhtXYdV19rDtImIiIiqoQVJCIiIqJKGJCIiIiIKmFAIiIiIqqEAYmIiIioEgYklVm+fDnCw8NhNBoRHR2NvXv3Kt2lm15SUhK6d+8Ob29vBAUFYeDAgTh58qRTm5KSEowfPx4BAQHw8vLCkCFDkJmZqVCPbw3z58+HIAiYMmWKvI/XuX5duHABTzzxBAICAuDu7o4OHTpg//798nFRFDFz5kyEhobC3d0dsbGx+P333xXs8c3Jbrfj1VdfRfPmzeHu7o6WLVti7ty5Ts/y4rWumx9//BEPP/wwwsLCIAgCNm3a5HS8Ntc1JycHCQkJ8PHxga+vL8aOHYuCgoIb7hsDkoqsX78eiYmJmDVrFg4ePIhOnTohLi4OWVlZSnftpvbDDz9g/Pjx2L17N5KTk1FaWor7778fhYWFcpupU6fiyy+/xIYNG/DDDz/g4sWLGDx4sIK9vrnt27cP7777Ljp27Oi0n9e5/ly5cgW9evWCm5sbvvnmG/z6669YtGgR/Pz85DZvvPEG3nzzTaxYsQJ79uyBp6cn4uLiUFJSomDPbz4LFizAO++8g2XLluH48eNYsGAB3njjDbz11ltyG17ruiksLESnTp2wfPnyao/X5romJCTg2LFjSE5OxubNm/Hjjz9i3LhxN945kVSjR48e4vjx4+Wf7Xa7GBYWJiYlJSnYq1tPVlaWCED84YcfRFEUxdzcXNHNzU3csGGD3Ob48eMiADE1NVWpbt608vPzxYiICDE5OVns3bu3OHnyZFEUeZ3r24svvijefffdNR53OBxiSEiIuHDhQnlfbm6uaDAYxE8++cQVXbxl9O/fX3zyySed9g0ePFhMSEgQRZHXur4AEDdu3Cj/XJvr+uuvv4oAxH379sltvvnmG1EQBPHChQs31B9WkFTCarXiwIEDiI2NlfdpNBrExsYiNTVVwZ7devLy8gAA/v7+AIADBw6gtLTU6dpHRkaiadOmvPZ1MH78ePTv39/pegK8zvXtiy++QFRUFP76178iKCgIXbp0wXvvvScfP336NDIyMpyut8lkQnR0NK/3derZsydSUlLw22+/AQB+/vln/PTTT3jggQcA8Fo3lNpc19TUVPj6+iIqKkpuExsbC41Ggz179tzQ+/NhtSqRnZ0Nu92O4OBgp/3BwcE4ceKEQr269TgcDkyZMgW9evVC+/btAQAZGRnQ6/Xw9fV1ahscHIyMjAwFennzWrduHQ4ePIh9+/ZVOcbrXL/+97//4Z133kFiYiJefvll7Nu3D5MmTYJer8eoUaPka1rdvym83tfnpZdegtlsRmRkJLRaLex2O+bNm4eEhAQA4LVuILW5rhkZGQgKCnI6rtPp4O/vf8PXngGJbivjx4/H0aNH8dNPPyndlVvOuXPnMHnyZCQnJ8NoNCrdnVuew+FAVFQUXn/9dQBAly5dcPToUaxYsQKjRo1SuHe3lk8//RRr1qzB2rVr0a5dOxw+fBhTpkxBWFgYr/UtjLfYVCIwMBBarbbKjJ7MzEyEhIQo1Ktby4QJE7B582Zs27YNd9xxh7w/JCQEVqsVubm5Tu157a/PgQMHkJWVha5du0Kn00Gn0+GHH37Am2++CZ1Oh+DgYF7nehQaGoq2bds67WvTpg3S0tIAQL6m/Dflxk2bNg0vvfQShg0bhg4dOmDEiBGYOnUqkpKSAPBaN5TaXNeQkJAqE5lsNhtycnJu+NozIKmEXq9Ht27dkJKSIu9zOBxISUlBTEyMgj27+YmiiAkTJmDjxo34/vvv0bx5c6fj3bp1g5ubm9O1P3nyJNLS0njtr0O/fv3wyy+/4PDhw/IWFRWFhIQE+Xte5/rTq1evKstV/Pbbb2jWrBkAoHnz5ggJCXG63mazGXv27OH1vk5FRUXQaJz/XGq1WjgcDgC81g2lNtc1JiYGubm5OHDggNzm+++/h8PhQHR09I114IaGeFO9WrdunWgwGMRVq1aJv/76qzhu3DjR19dXzMjIULprN7VnnnlGNJlM4vbt28X09HR5Kyoqkts8/fTTYtOmTcXvv/9e3L9/vxgTEyPGxMQo2Otbw9Wz2ESR17k+7d27V9TpdOK8efPE33//XVyzZo3o4eEh/t///Z/cZv78+aKvr6/43//+Vzxy5Ig4YMAAsXnz5mJxcbGCPb/5jBo1SmzcuLG4efNm8fTp0+Lnn38uBgYGii+88ILchte6bvLz88VDhw6Jhw4dEgGIixcvFg8dOiSePXtWFMXaXdf4+HixS5cu4p49e8SffvpJjIiIEIcPH37DfWNAUpm33npLbNq0qajX68UePXqIu3fvVrpLNz0A1W4ffvih3Ka4uFh89tlnRT8/P9HDw0McNGiQmJ6erlynbxGVAxKvc/368ssvxfbt24sGg0GMjIwUV65c6XTc4XCIr776qhgcHCwaDAaxX79+4smTJxXq7c3LbDaLkydPFps2bSoajUaxRYsW4iuvvCJaLBa5Da913Wzbtq3af59HjRolimLtruvly5fF4cOHi15eXqKPj484ZswYMT8//4b7JojiVUuBEhERERHHIBERERFVxoBEREREVAkDEhEREVElDEhERERElTAgEREREVXCgERERERUCQMSERERUSUMSERE9UQQBGzatEnpbhBRPWBAIqJbwujRoyEIQpUtPj5e6a4R0U1Ip3QHiIjqS3x8PD788EOnfQaDQaHeENHNjBUkIrplGAwGhISEOG1+fn4ApNtf77zzDh544AG4u7ujRYsW+Oyzz5xe/8svv+C+++6Du7s7AgICMG7cOBQUFDi1+eCDD9CuXTsYDAaEhoZiwoQJTsezs7MxaNAgeHh4ICIiAl988UXDfmgiahAMSER023j11VcxZMgQ/Pzzz0hISMCwYcNw/PhxAEBhYSHi4uLg5+eHffv2YcOGDfjuu++cAtA777yD8ePHY9y4cfjll1/wxRdf4M4773R6jzlz5uCxxx7DkSNH8OCDDyIhIQE5OTku/ZxEVA9u+HG3REQqMGrUKFGr1Yqenp5O27x580RRFEUA4tNPP+30mujoaPGZZ54RRVEUV65cKfr5+YkFBQXy8a+++krUaDRiRkaGKIqiGBYWJr7yyis19gGAOGPGDPnngoICEYD4zTff1NvnJCLX4BgkIrpl9O3bF++8847TPn9/f/n7mJgYp2MxMTE4fPgwAOD48ePo1KkTPD095eO9evWCw+HAyZMnIQgCLl68iH79+l2zDx07dpS/9/T0hI+PD7Kysur6kYhIIQxIRHTL8PT0rHLLq764u7vXqp2bm5vTz4IgwOFwNESXiKgBcQwSEd02du/eXeXnNm3aAADatGmDn3/+GYWFhfLxnTt3QqPRoHXr1vD29kZ4eDhSUlJc2mciUgYrSER0y7BYLMjIyHDap9PpEBgYCADYsGEDoqKicPfdd2PNmjXYu3cv3n//fQBAQkICZs2ahVGjRmH27Nm4dOkSJk6ciBEjRiA4OBgAMHv2bDz99NMICgrCAw88gPz8fOzcuRMTJ0507QclogbHgEREt4wtW7YgNDTUaV/r1q1x4sQJANIMs3Xr1uHZZ59FaGgoPvnkE7Rt2xYA4OHhga1bt2Ly5Mno3r07PDw8MGTIECxevFg+16hRo1BSUoJ//etfeP755xEYGIhHH33UdR+QiFxGEEVRVLoTREQNTRAEbNy4EQMHDlS6K0R0E+AYJCIiIqJKGJCIiIiIKuEYJCK6LXA0ARFdD1aQiIiIiCphQCIiIiKqhAGJiIiIqBIGJCIiIqJKGJCIiIiIKmFAIiIiIqqEAYmIiIioEgYkIiIiokoYkIiIiIgq+X806vfYe8zhPwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history_['loss'], label='Train Loss')\n",
    "plt.plot(history.history_['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Our Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
